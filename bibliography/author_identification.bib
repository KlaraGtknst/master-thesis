
@article{stamatatos_survey_2009,
	title = {A survey of modern authorship attribution methods},
	volume = {60},
	issn = {1532-2890},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.21001},
	doi = {10.1002/asi.21001},
	abstract = {Authorship attribution supported by statistical or computational methods has a long history starting from the 19th century and is marked by the seminal study of Mosteller and Wallace (1964) on the authorship of the disputed “Federalist Papers.” During the last decade, this scientific field has been developed substantially, taking advantage of research advances in areas such as machine learning, information retrieval, and natural language processing. The plethora of available electronic texts (e.g., e-mail messages, online forum messages, blogs, source code, etc.) indicates a wide variety of applications of this technology, provided it is able to handle short and noisy text from multiple candidate authors. In this article, a survey of recent advances of the automated approaches to attributing authorship is presented, examining their characteristics for both text representation and text classification. The focus of this survey is on computational requirements and settings rather than on linguistic or literary issues. We also discuss evaluation methodologies and criteria for authorship attribution studies and list open questions that will attract future work in this area.},
	language = {en},
	number = {3},
	urldate = {2025-03-08},
	journal = {Journal of the American Society for Information Science and Technology},
	author = {Stamatatos, Efstathios},
	year = {2009},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.21001},
	pages = {538--556},
	file = {Full Text PDF:/Users/klara/Zotero/storage/ZYKIXQAS/Stamatatos - 2009 - A survey of modern authorship attribution methods.pdf:application/pdf;Snapshot:/Users/klara/Zotero/storage/Q5JSF69B/asi.html:text/html},
}

@article{stein_intrinsic_2011,
	title = {Intrinsic plagiarism analysis},
	volume = {45},
	copyright = {http://www.springer.com/tdm},
	issn = {1574-020X, 1574-0218},
	url = {http://link.springer.com/10.1007/s10579-010-9115-y},
	doi = {10.1007/s10579-010-9115-y},
	abstract = {Research in automatic text plagiarism detection focuses on algorithms that compare suspicious documents against a collection of reference documents. Recent approaches perform well in identifying copied or modiﬁed foreign sections, but they assume a closed world where a reference collection is given. This article investigates the question whether plagiarism can be detected by a computer program if no reference can be provided, e.g., if the foreign sections stem from a book that is not available in digital form. We call this problem class intrinsic plagiarism analysis; it is closely related to the problem of authorship veriﬁcation.},
	language = {en},
	number = {1},
	urldate = {2025-03-08},
	journal = {Language Resources and Evaluation},
	author = {Stein, Benno and Lipka, Nedim and Prettenhofer, Peter},
	month = mar,
	year = {2011},
	pages = {63--82},
	file = {Stein et al. - 2011 - Intrinsic plagiarism analysis.pdf:/Users/klara/Zotero/storage/4Z53GB8R/Stein et al. - 2011 - Intrinsic plagiarism analysis.pdf:application/pdf},
}

@article{ayele_overview_2024,
	title = {Overview of {PAN} 2024: {Multi}-{Author} {Writing} {Style} {Analysis}, {Multilingual} {Text} {Detoxification}, {Oppositional} {Thinking} {Analysis}, and {Generative} {AI} {Authorship} {Verification}},
	abstract = {The goal of the PAN lab is to advance the state of the art in text forensics and stylometry through an objective evaluation of new and established methods on new benchmark datasets. In 2024, we organized four shared tasks: (1) multi-author writing style analysis, which we continue from 2023; (2) multilingual text detoxification, a new task that aims to re-formulate text in a non-toxic way for multiple languages; (3) oppositional thinking analysis, a new task that aims to discriminate critical thinking from conspiracy narratives and identify their core actors; and (4) generative AI authorship verification, which formulates the detection of AI-generated text as an authorship problem. PAN 2024 concluded as one of our most successful editions with 74 notebook papers by 147 participating teams.},
	language = {en},
	author = {Ayele, Abinew Ali and Babakov, Nikolay and Bevendorff, Janek and Casals, Xavier Bonet and Chulvi, Berta and Dementieva, Daryna and Elnagar, Ashaf and Freitag, Dayne and Fröbe, Maik and Korenčić, Damir and Mayerl, Maximilian and Moskovskiy, Daniil and Mukherjee, Animesh and Panchenko, Alexander and Potthast, Martin and Rangel, Francisco and Rizwan, Naquee and Rosso, Paolo and Schneider, Florian and Smirnova, Alisa and Stamatatos, Efstathios and Stakovskii, Elisei and Stein, Benno and Taulé, Mariona and Ustalov, Dmitry and Wang, Xintong and Wiegmann, Matti and Yimam, Seid Muhie and Zangerle, Eva},
	year = {2024},
	file = {Ayele et al. - Overview of PAN 2024 Multi-Author Writing Style A.pdf:/Users/klara/Zotero/storage/QBR9KC9B/Ayele et al. - Overview of PAN 2024 Multi-Author Writing Style A.pdf:application/pdf},
}

@article{zangerle_overview_2024,
	title = {Overview of the {Multi}-{Author} {Writing} {Style} {Analysis} {Task} at {PAN} 2024},
	abstract = {Analyzing the writing style of individual authors in texts in which several authors are involved is a fundamental task in attributing authorship and detecting plagiarism, as it makes it possible to identify the points at which authorship changes. This year’s multi-author writing style analysis task focuses on identifying all instances of paragraph-level writing style changes within a given text. We provide datasets with three different degrees of topical homogeneity to investigate how different degrees of topic consistency affect the detection of writing style changes. This paper gives an overview of the task, its definition and the data used, the approaches proposed by the participants, and the results obtained.},
	language = {en},
	author = {Zangerle, Eva and Mayerl, Maximilian and Potthast, Martin and Stein, Benno},
	year = {2024},
	file = {Zangerle et al. - Overview of the Multi-Author Writing Style Analysi.pdf:/Users/klara/Zotero/storage/XDW2LQF7/Zangerle et al. - Overview of the Multi-Author Writing Style Analysi.pdf:application/pdf},
}

@inproceedings{emmery_adversarial_2021,
	address = {Online},
	title = {Adversarial {Stylometry} in the {Wild}: {Transferable} {Lexical} {Substitution} {Attacks} on {Author} {Profiling}},
	shorttitle = {Adversarial {Stylometry} in the {Wild}},
	url = {https://aclanthology.org/2021.eacl-main.203},
	doi = {10.18653/v1/2021.eacl-main.203},
	abstract = {Written language contains stylistic cues that can be exploited to automatically infer a variety of potentially sensitive author information. Adversarial stylometry intends to attack such models by rewriting an author’s text. Our research proposes several components to facilitate deployment of these adversarial attacks in the wild, where neither data nor target models are accessible. We introduce a transformerbased extension of a lexical replacement attack, and show it achieves high transferability when trained on a weakly labeled corpus—decreasing target model performance below chance. While not completely inconspicuous, our more successful attacks also prove notably less detectable by humans. Our framework therefore provides a promising direction for future privacy-preserving adversarial attacks.},
	language = {en},
	urldate = {2025-04-10},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Emmery, Chris and Kádár, Ákos and Chrupała, Grzegorz},
	year = {2021},
	pages = {2388--2402},
	file = {Emmery et al. - 2021 - Adversarial Stylometry in the Wild Transferable L.pdf:/Users/klara/Zotero/storage/4JTXSK7D/Emmery et al. - 2021 - Adversarial Stylometry in the Wild Transferable L.pdf:application/pdf},
}

@inproceedings{bevendorff_generalizing_2019,
	address = {Minneapolis, Minnesota},
	title = {Generalizing {Unmasking} for {Short} {Texts}},
	url = {http://aclweb.org/anthology/N19-1068},
	doi = {10.18653/v1/N19-1068},
	abstract = {Authorship veriﬁcation is the problem of inferring whether two texts were written by the same author. For this task, unmasking is one of the most robust approaches as of today with the major shortcoming of only being applicable to book-length texts. In this paper, we present a generalized unmasking approach which allows for authorship veriﬁcation of texts as short as four printed pages with very high precision at an adjustable recall tradeoff. Our generalized approach therefore reduces the required material by orders of magnitude, making unmasking applicable to authorship cases of more practical proportions. The new approach is on par with other state-ofthe-art techniques that are optimized for texts of this length: it achieves accuracies of 75–80 \%, while also allowing for easy adjustment to forensic scenarios that require higher levels of conﬁdence in the classiﬁcation.},
	language = {en},
	urldate = {2025-04-14},
	booktitle = {Proceedings of the 2019 {Conference} of the {North}},
	publisher = {Association for Computational Linguistics},
	author = {Bevendorff, Janek and Stein, Benno and Hagen, Matthias and Potthast, Martin},
	year = {2019},
	pages = {654--659},
	file = {Bevendorff et al. - 2019 - Generalizing Unmasking for Short Texts.pdf:/Users/klara/Zotero/storage/GYIDVVE6/Bevendorff et al. - 2019 - Generalizing Unmasking for Short Texts.pdf:application/pdf},
}

@inproceedings{bevendorff_bias_2019,
	address = {Florence, Italy},
	title = {Bias {Analysis} and {Mitigation} in the {Evaluation} of {Authorship} {Verification}},
	url = {https://www.aclweb.org/anthology/P19-1634},
	doi = {10.18653/v1/P19-1634},
	abstract = {The PAN series of shared tasks is well known for its continuous and high quality research in the ﬁeld of digital text forensics. Among others, PAN contributions include original corpora, tailored benchmarks, and standardized experimentation platforms. In this paper we review, theoretically and practically, the authorship veriﬁcation task and conclude that the underlying experiment design cannot guarantee pushing forward the state of the art—in fact, it allows for top benchmarking with a surprisingly straightforward approach. In this regard, we present a “Basic and Fairly Flawed” (BAFF) authorship veriﬁer that is on a par with the best approaches submitted so far, and that illustrates sources of bias that should be eliminated. We pinpoint these sources in the evaluation chain and present a reﬁned authorship corpus as effective countermeasure.},
	language = {en},
	urldate = {2025-04-14},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Bevendorff, Janek and Hagen, Matthias and Stein, Benno and Potthast, Martin},
	year = {2019},
	pages = {6301--6306},
	file = {Bevendorff et al. - 2019 - Bias Analysis and Mitigation in the Evaluation of .pdf:/Users/klara/Zotero/storage/HIJXCAYF/Bevendorff et al. - 2019 - Bias Analysis and Mitigation in the Evaluation of .pdf:application/pdf},
}

@article{bischoff_importance_2020,
	title = {The {Importance} of {Suppressing} {Domain} {Style} in {Authorship} {Analysis}},
	abstract = {The prerequisite of many approaches to authorship analysis is a representation of writing style. But despite decades of research, it still remains unclear to what extent commonly used and widely accepted representations like character trigram frequencies actually represent an author’s writing style, in contrast to more domain-speciﬁc style components or even topic. We address this shortcoming for the ﬁrst time in a novel experimental setup of ﬁxed authors but swapped domains between training and testing. With this setup, we reveal that approaches using character trigram features are highly susceptible to favor domain information when applied without attention to domains, suffering drops of up to 55.4 percentage points in classiﬁcation accuracy under domain swapping. We further propose a new remedy based on domain-adversarial learning and compare it to ones from the literature based on heuristic rules. Both can work well, reducing accuracy losses under domain swapping to 3.6\% and 3.9\%, respectively.},
	language = {en},
	author = {Bischoff, Sebastian and Deckers, Niklas and Schliebs, Marcel and Hagen, Matthias and Stamatatos, Efstathios and Stein, Benno and Thies, Ben and Potthast, Martin},
	year = {2020},
	file = {Bischoff et al. - The Importance of Suppressing Domain Style in Auth.pdf:/Users/klara/Zotero/storage/9Q76AM5F/Bischoff et al. - The Importance of Suppressing Domain Style in Auth.pdf:application/pdf},
}

@article{bevendorff_overview_2024,
	title = {Overview of the “{Voight}-{Kampff}” {Generative} {AI} {Authorship} {Verification} {Task} at {PAN} and {ELOQUENT}{\textasciitilde}2024},
	abstract = {The “Voight-Kampff” Generative AI Authorship Verification task aims to determine whether a text was generated by an AI or written by a human. As in its fictional inspiration,1 the Voight-Kampff task structures AI detection as a builder-breaker challenge: The builders, participants in the PAN lab, submit software to detect AI-written text and the breakers, participants in the ELOQUENT lab, submit AI-written text with the goal of fooling the builders. We formulate the task in a way that is reminiscent of a traditional authorship verification problem, where given a pair of texts, their human or machine authorship is to be inferred. For this first task installment, we further restrict the problem so that each pair is guaranteed to contain one human and one machine text. Hence the task description reads: Given two texts, one authored by a human, one by a machine: pick out the human.},
	language = {en},
	author = {Bevendorff, Janek and Wiegmann, Matti and Karlgren, Jussi and Dürlich, Luise and Gogoulou, Evangelia and Talman, Aarne and Stamatatos, Efstathios and Potthast, Martin and Stein, Benno},
	year = {2024},
	file = {Bevendorff et al. - Overview of the “Voight-Kampff” Generative AI Auth.pdf:/Users/klara/Zotero/storage/6L3LMH8A/Bevendorff et al. - Overview of the “Voight-Kampff” Generative AI Auth.pdf:application/pdf},
}

@article{bevendorff_divergence-based_2020,
	title = {On divergence-based author obfuscation: {An} attack on the state of the art in statistical authorship verification},
	volume = {62},
	issn = {2196-7032, 1611-2776},
	shorttitle = {On divergence-based author obfuscation},
	url = {https://www.degruyter.com/document/doi/10.1515/itit-2019-0046/html},
	doi = {10.1515/itit-2019-0046},
	abstract = {Authorship veriﬁcation is the task of determining whether two texts were written by the same author based on a writing style analysis. Author obfuscation is the adversarial task of preventing a successful veriﬁcation by altering a text’s style so that it does not resemble that of its original author anymore. This paper introduces new algorithms for both tasks and reports on a comprehensive evaluation to ascertain the merits of the state of the art in authorship veriﬁcation to withstand obfuscation. After introducing a new generalization of the well-known unmasking algorithm for short texts, thus completing our collection of state-of-the-art algorithms for veriﬁcation, we introduce an approach that (1) models writing style diﬀerence as the Jensen-Shannon distance between the character n-gram distributions of texts, and (2) manipulates an author’s writing style in a sophisticated manner using heuristic search. For obfuscation, we explore the huge space of textual variants in order to ﬁnd a paraphrased version of the to-be-obfuscated text that has a suﬃciently high Jensen-Shannon distance at minimal costs in terms of text quality loss. We analyze, quantify, and illustrate the rationale of this approach, deﬁne paraphrasing operators, derive text length-invariant thresholds for termination, and develop an eﬀective obfuscation framework. Our authorship obfuscation approach defeats the presented state-of-the-art veriﬁcation approaches, while keeping text changes at a minimum. As a ﬁnal contribution, we discuss and experimentally evaluate a reverse obfuscation attack against our obfuscation approach as well as possible remedies.},
	language = {en},
	number = {2},
	urldate = {2025-04-14},
	journal = {it - Information Technology},
	author = {Bevendorff, Janek and Wenzel, Tobias and Potthast, Martin and Hagen, Matthias and Stein, Benno},
	month = apr,
	year = {2020},
	pages = {99--115},
	file = {Bevendorff et al. - 2020 - On divergence-based author obfuscation An attack .pdf:/Users/klara/Zotero/storage/TCAVY4H2/Bevendorff et al. - 2020 - On divergence-based author obfuscation An attack .pdf:application/pdf},
}

@inproceedings{bevendorff_smauc_2023,
	address = {Santa Fe, NM, USA},
	title = {{SMAuC} - {The} {Scientific} {Multi}-{Authorship} {Corpus}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350399318},
	url = {https://ieeexplore.ieee.org/document/10266094/},
	doi = {10.1109/JCDL57899.2023.00013},
	abstract = {The rapidly growing volume of scientific publications offers an interesting challenge for research on methods for analyzing the authorship of documents with one or more authors. However, most existing datasets lack scientific documents or the necessary metadata for constructing new experiments and test cases. We introduce SMAuC, a comprehensive, metadata-rich corpus tailored to scientific authorship analysis. Comprising over 3 million publications across various disciplines from over 5 million authors, SMAuC is the largest openly accessible corpus for this purpose. It encompasses scientific texts from humanities and natural sciences, accompanied by extensive, curated metadata, including unambiguous author IDs. SMAuC aims to significantly advance the domain of authorship analysis in scientific texts.},
	language = {en},
	urldate = {2025-04-14},
	booktitle = {2023 {ACM}/{IEEE} {Joint} {Conference} on {Digital} {Libraries} ({JCDL})},
	publisher = {IEEE},
	author = {Bevendorff, Janek and Sauer, Philipp and Gienapp, Lukas and Kircheis, Wolfgang and Körner, Erik and Stein, Benno and Potthast, Martin},
	month = jun,
	year = {2023},
	pages = {25--29},
	file = {Bevendorff et al. - 2023 - SMAuC - The Scientific Multi-Authorship Corpus.pdf:/Users/klara/Zotero/storage/WSEDD5NK/Bevendorff et al. - 2023 - SMAuC - The Scientific Multi-Authorship Corpus.pdf:application/pdf},
}

@misc{tyo_state_2022,
	title = {On the {State} of the {Art} in {Authorship} {Attribution} and {Authorship} {Verification}},
	url = {http://arxiv.org/abs/2209.06869},
	doi = {10.48550/arXiv.2209.06869},
	abstract = {Statistics While older methods focused on small sets of summary statistics, more modern methods are able to combine all of these into a single model. Weerasinghe et al. (2021) provide the best example of this, calculating a plethora of hand-crafted features and Ngrams for each document (distribution of word lengths, hapax-legomena, Maas’ a2, Herdan’s Vm, and more). The authors take the difference between these large feature vectors for two texts and then train a logistic regression classiﬁer to predict if the texts were written by the same author or not. Despite its simplicity, this method performs well.},
	language = {en},
	urldate = {2025-04-14},
	publisher = {arXiv},
	author = {Tyo, Jacob and Dhingra, Bhuwan and Lipton, Zachary C.},
	month = oct,
	year = {2022},
	note = {arXiv:2209.06869 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Tyo et al. - 2022 - On the State of the Art in Authorship Attribution .pdf:/Users/klara/Zotero/storage/TK6RXFEV/Tyo et al. - 2022 - On the State of the Art in Authorship Attribution .pdf:application/pdf},
}

@article{koppel_authorship_2011,
	title = {Authorship attribution in the wild},
	volume = {45},
	issn = {1574-0218},
	url = {https://doi.org/10.1007/s10579-009-9111-2},
	doi = {10.1007/s10579-009-9111-2},
	abstract = {Most previous work on authorship attribution has focused on the case in which we need to attribute an anonymous document to one of a small set of candidate authors. In this paper, we consider authorship attribution as found in the wild: the set of known candidates is extremely large (possibly many thousands) and might not even include the actual author. Moreover, the known texts and the anonymous texts might be of limited length. We show that even in these difficult cases, we can use similarity-based methods along with multiple randomized feature sets to achieve high precision. Moreover, we show the precise relationship between attribution precision and four parameters: the size of the candidate set, the quantity of known-text by the candidates, the length of the anonymous text and a certain robustness score associated with a attribution.},
	language = {en},
	number = {1},
	urldate = {2025-04-14},
	journal = {Language Resources and Evaluation},
	author = {Koppel, Moshe and Schler, Jonathan and Argamon, Shlomo},
	month = mar,
	year = {2011},
	keywords = {Authorship attribution, Open candidate set, Randomized feature set},
	pages = {83--94},
	file = {Full Text PDF:/Users/klara/Zotero/storage/68IC9WZN/Koppel et al. - 2011 - Authorship attribution in the wild.pdf:application/pdf},
}
