\section{Definitions}
\label{sec:definitions}


% \begin{definition}
%     []
% \end{definition}

\begin{definition}
    [Text]
    A sequence of tokens or characters grouped into sentences \cite{elmanarelbouanani_authorship_2014}.
\end{definition}

\begin{definition}
    [Token]
    A token can be a word, a number or a punctuation mark \cite{elmanarelbouanani_authorship_2014}.
\end{definition}

\begin{definition}
    [Monograph]
    Single author document \cite{bevendorff_smauc_2023}.
\end{definition}

\begin{definition}
    [Multi-author (i.e. Collaborative) publication]
    Document with multiple authors \cite{bevendorff_smauc_2023}.
\end{definition}

\begin{definition}
    [Author profiling]
    Task of inferring an extensive set of (sensitive) personal information.
    This includes sociolinguistic attributes like age, gender, occupation, education, socio-economic status, cultural background, 
    language familiarity and mental health issues 
    \cite{emmery_adversarial_2021,stamatatos_survey_2009,elmanarelbouanani_authorship_2014}.
    The task is also referred to as author characterization \cite{stamatatos_survey_2009,elmanarelbouanani_authorship_2014}.
\end{definition}

\begin{definition}
    [Stylometry]
    Liguistic research area, which refers to the (statistical) analysis of authorial/ literally style \cite{elmanarelbouanani_authorship_2014,neal_surveying_2018}.
    Stylometry assumes that style is quantifiably measurable for evaluation of distinctive qualities \cite{neal_surveying_2018}.
    The construction of models for the quantification of writing style, text complexity, and grading level assessment.
    Stylometric features include lexical, syntactic and structural features \cite{stein_intrinsic_2011}.
    In other words, stylometry is the statistical analysis of literary style between one writer or genre and another \cite{tyo_state_2022}.
    Research includes five subtasks \cite{neal_surveying_2018}:
    \begin{itemize}
        \item \ac{aa}
        \item \ac{av}
        \item Author profiling
        \item \todo{stylochronometry}
        \item adversarial stylometry
    \end{itemize}
\end{definition}

\begin{definition}
    [Stylistics]
    The study of stylometric features \cite{elmanarelbouanani_authorship_2014,abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Author writing style]
    Among others, syntactic structure of sentences in a document \cite{jafariakinabad_self_supervised_2022}.
\end{definition}

\citet{elmanarelbouanani_authorship_2014} claim there are four (five \cite{abbasi_writeprints_2008}) types of writing style/ stylistic features:
\begin{itemize}
    \item Lexical features \citet{elmanarelbouanani_authorship_2014,abbasi_writeprints_2008}
    \item Syntactic features \citet{elmanarelbouanani_authorship_2014,abbasi_writeprints_2008}
    \item Structural features \citet{elmanarelbouanani_authorship_2014,abbasi_writeprints_2008}
    \item Content-specific features \citet{elmanarelbouanani_authorship_2014,abbasi_writeprints_2008}
    \item Idiosyncratic features \citet{abbasi_writeprints_2008}
\end{itemize}

\begin{definition}
    [Online stylometric analysis]
    The analysis of authors style in online texts \cite{abbasi_writeprints_2008}.
    \citet{abbasi_writeprints_2008} define online texts as any textual documents that may be found in an online setting, 
    including computer-mediated communication, non-literary electronic documents (e.g., student essays, mews, articles, etc.), and program code.
\end{definition}

\begin{definition}
    [Style markers]
    Taxonomies of features to quantify the writing style \cite{stamatatos_survey_2009}.
\end{definition}

\begin{definition}
    [Stylistic features]
    Features that are the attributes or writing-style markers that are the most effective discriminators of authorship \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Lexical features]
    Lexical features are common features used in stylometry.
    They are character- (i.e. character (n-gram) frequency, ...) 
    or word-based (i.e. average word~\cite{stein_intrinsic_2011}, sentence length~\cite{stein_intrinsic_2011,abbasi_writeprints_2008}, 
    line length~\cite{abbasi_writeprints_2008}, word length distribution~\cite{abbasi_writeprints_2008}, 
    vocabulary richness~\cite{abbasi_writeprints_2008} ...) features. 
    These features consider text as a mere sequence of word-tokens or characters, respectively \cite{stamatatos_survey_2009}.
    Word features are more complex than character features \cite{stamatatos_survey_2009}.
\end{definition}

\begin{definition}
    [Syntactic features]
    Syntactic features include function words, punctuation, and \ac{pos} tag $n$-grams \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Structural features]
    Structural features include text organization, layout, file extensions, font, sizes, colours, 
    use of braces and comments (for analysing computer programs) \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Content-specific features]
    Content-specific features include important keywords and phrases on certain topics such as word $n$-grams \cite{abbasi_writeprints_2008}.
    Domain-specific features include ratios of quoted words and external links, number of paragraphs, 
    and paragraphs average length for the news article domain \cite{potthast_stylometric_2018}
\end{definition}

\begin{definition}
    [Idiosyncratic features]
    Idiosyncratic features include misspellings, grammatical mistakes, and other usage anomalies.
    Such features are extracted using spelling and grammar checking tools and dictionaries \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Feature-set type]
    There are two types of feature sets \cite{abbasi_writeprints_2008}:
    \begin{itemize}
        \item Author-group-level where one set of features is applied across all authors.
        \item Individual-author-level where each author has a unique set of features (e.g., 10 authors = 10 feature sets; 5000 most frequent character $n$-grams per author).
    \end{itemize}
    Individual-author-level features are effective for feature categories with potentially large feature spaces, such as $n$-grams or misspellings.
    However, standard machine learning techniques typically require a fixed feature set for all authors \cite{abbasi_writeprints_2008}.
    Traditional single-author-group-level feature sets include \acp{svm} and \ac{pca} \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Static features]
    Static features include context-free categories such as function words, 
    word-length distributions, vocabulary richness measures, etc. \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Dynamic features]
    Dynamic features are context-dependent attributes and include $n$-grams and misspelled words \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Stability]
    Stability refers to how often a feature changes across authors and documents for a constant topic.
    \citet{abbasi_writeprints_2008} state that nouns are more stable than function words and thus, 
    function words are better stylistic discriminators than nouns 
    since using function words involves making choices between sets of synonyms.
\end{definition}

\begin{definition}
    [Adversarial Stylometry]
    Attack models that automatically infer a variety of potentially sensitive author information.
    These attacks are not to be confused with adversarial learning \cite{emmery_adversarial_2021}.
\end{definition}

\begin{definition}
    [Closed world]
    In the realm of plagiarism detection, closed world refers to the assumption 
    that a reference collection $D$ of documents, 
    that are supposed to be compared to the possibly plagiarized text, is given \cite{stein_intrinsic_2011}.
    In the realm of \ac{av} texts in the test set are assumed to be written by one of the authors in the training set \cite{boenninghoff_o2d2_2021}.
\end{definition}

\begin{definition}
    [Plagiarism]
    In the context of texts, plagiarism is the usage of another author's information, language, 
    or writing without properly acknowledging the original source \cite{stein_intrinsic_2011}.
    \citet{elmanarelbouanani_authorship_2014} define plagiarism as the complete or partial replication 
    of a piece of work with or without permission of the original author.
\end{definition}

\begin{definition}
    [Plagiarism detection]
    The task of identifying plagiarized text \cite{stein_intrinsic_2011}, i.e. finding similarities between two texts \cite{stamatatos_survey_2009}.
    Plagiarism detection uses similarity detection, determining whether multiple pieces of work were produced by a single author 
    without necessarly identifying the author \cite{elmanarelbouanani_authorship_2014}.
\end{definition}

\begin{definition}
    [Intrinsic plagiarism detection]
    This task can be understood as a more general form of \ac{av}.
    By analysing undeclared changes in writing style, potential plagiarism can be detected.
    Opposed to \ac{av}, where the decision is made based on the whole text, 
    intrinsic plagiarism detects plagiarism on a section level \cite{stein_intrinsic_2011}.
    Intrinsic analysis does not use any information on authorship from external sources \cite{zangerle_overview_2024}.
\end{definition}

\begin{definition}
    [Authorship analysing]
    This problem devises into two \textcolor{orange}{(i.e. first two acc. to \cite{stein_intrinsic_2011}, all acc. to \cite{stamatatos_survey_2009})} subtasks \cite{stein_intrinsic_2011}:
    \begin{itemize}
        \item \ac{aa} \cite{stein_intrinsic_2011}
        \item \ac{av} \cite{stein_intrinsic_2011,stamatatos_survey_2009}
        \item Plagiarism detection \cite{stamatatos_survey_2009}
        \item Author profiling \cite{stamatatos_survey_2009}
        \item Detection of stylistic inconsistencies (i.e. in collaborative writing) \cite{stamatatos_survey_2009}
    \end{itemize}
\end{definition}

\begin{definition}
    [\ac{aa}]   % authorship attribution
    The task of determining the author of a text based on textual features 
    given a (canonical) set of candidate authors with undisputed writing samples 
    \cite{stein_intrinsic_2011,stamatatos_survey_2009,tyo_state_2022,bischoff_importance_2020,barlas_cross_domain_2020,altakrori_topic_2021,bevendorff_divergence_based_2020,elmanarelbouanani_authorship_2014,abbasi_writeprints_2008}.
    In terms of machine learning, this is a multiclass, single-label text categorization task \cite{stamatatos_survey_2009,elmanarelbouanani_authorship_2014} or text classification task \cite{elmanarelbouanani_authorship_2014}.
    The task is also referred to as author(ship) identification \cite{stamatatos_survey_2009,elmanarelbouanani_authorship_2014}.
    \citet{barlas_cross_domain_2020} express the \ac{aa} task as a tuple $(A,K,U)$, 
    where $A$ is the set of authors, $K=\underset{a\in A}{\cup}K_a$ is the set of known texts and $U$ is the set of unknown texts.
    If closed-set \ac{aa}: Each text $d \in U$ is attributed to exactly one author $a \in A$.
    If cross-topic(/-genre) \ac{aa}: The topic(/genre) of documents in $d \in U$ is distinct 
    with respect to the topics(/genres) found in $K$ \cite{barlas_cross_domain_2020}. 
\end{definition}

\citet{elmanarelbouanani_authorship_2014} describe the workflow of \ac{aa} as follows:
\begin{enumerate}
    \item Data cleaning
    \item Feature extraction
    \item Normalization
    \item Converting each text into a feature vector, where author is the class label
    \item Split the dataset into training and test set
\end{enumerate}
Common classifiers include \ac{svm}, decision trees, and \acp{nn} \cite{elmanarelbouanani_authorship_2014}.

\begin{definition}
    [\ac{av}]   % authorship verification
    Given a set of writing samples of author $A$ and a text $t$,    % tyo_state_2022: only one wrinting sample
    the task is to determine whether $t$ was written by $A$ \cite{stein_intrinsic_2011,stamatatos_survey_2009,koppel_authorship_2011,tyo_state_2022,kocher_unine_2015}.
    This task can also be formulated as whether two texts $t_1$ and $t_2$ are written by the same author 
    \cite{bevendorff_generalizing_2019,bevendorff_divergence_based_2020,embarcadero_ruiz_graph_based_2022,rivera_soto_learning_2021,ordonez_will_2020,futrzynski_pairwise_2021,weerasinghe_feature_vector_difference_2021}.
    % Gespräch Martin Potthast 19.05.2025: problem formulation 2 is less common and in the context of very sparse (metadata) information
    Related research areas include \cite{stein_intrinsic_2011}:
    \begin{itemize}
        \item stylometry
        \item outlier analysis and meta learning
        \item symbolic knowledge representation, i.e. \todo{knownledge representation, deduction, heuristic inference}
    \end{itemize}
    \citet{tyo_state_2022} state that \ac{av} is the fundamental problem of \ac{aa} \cite{tyo_state_2022}, 
    where there is only one candidate author \cite{barlas_cross_domain_2020}.
    \citet{elmanarelbouanani_authorship_2014} consider \ac{av} a similarity detection task.
    Use cases include plagiarism detection, moderation of user-generated content, historical \ac{aa}, and forensic analysis \cite{rivera_soto_learning_2021}.
\end{definition}

\begin{definition}
    [Similarity detection]
    The task of comparing anonymous texts against other anonymous texts to assess the degree of similarity \cite{abbasi_writeprints_2008}.
    In the context of \ac{av}, the task is to determine whether two texts are produced by the same person without knowing the real author of the document \cite{elmanarelbouanani_authorship_2014}.
\end{definition}

\begin{definition}
    [Message-level analysis]
    The analysis attempts to categorize individual texts (e.g., whether an email was authored by an email address) \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Identity-level analysis]
    The analysis attempts to classify individuals belonging to a particular entity 
    (e.g., whether different email addresses belong to the same entity).
    Identity-level analysis' categorization is based on all texts written by that identity.
    Hence, there are larger text samples than for message-level analysis, facilitating the task.
    If the task is framed as classification/ID identification, the disputed identity is assigned to the identity with the highest similarity among the known identities.
    If the task is framed as similarity detection task, all identities with a similarity score above a certain threshold are grouped together and 
    considered to belong to the same entity \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{table}[]
    \centering
    \caption{Building blocks for \ac{av} from \cite{stein_intrinsic_2011}.}
    \label{tab:authorship_verification_blocks}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{|l|lll|l|}
    \hline
    \rowcolor[HTML]{EFEFEF} 
    Pre-analysis & \multicolumn{3}{l|}{\cellcolor[HTML]{EFEFEF}Modeling and classifier methods} & Post-processing \\ \hline
    \rowcolor[HTML]{EFEFEF} 
    Impurity assessment & \multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}Decomposition strategy} & \multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}Style model construction} & Outlier identification & Outlier post-processing \\ \hline
    Document length analysis & \multicolumn{1}{l|}{Uniform length} & \multicolumn{1}{l|}{Lexical character features} & One-class density estimation & Heuristric voting \\
    Genre Analysis & \multicolumn{1}{l|}{Structural boundaries} & \multicolumn{1}{l|}{Lexical word features} & One-class boundary estimation & Citation analysis \\
    Analysis of issuing institution & \multicolumn{1}{l|}{Text element boundaries} & \multicolumn{1}{l|}{Syntactical features} & One-class reconstruction & Human inspection \\
     & \multicolumn{1}{l|}{Topical boundaries} & \multicolumn{1}{l|}{Structural features} & Two-class discrimination & Unmasking \\
     & \multicolumn{1}{l|}{Stylistic boundaries} & \multicolumn{1}{l|}{Language modeling} &  & Qsum \\
     & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} &  & Batch means
    \end{tabular}%
    }
\end{table}
Post-processing to avoid false positives, c.f. \citet{stein_intrinsic_2011} for approaches.

\begin{definition}
    [Meta learning]
    \todo{Based on learning successes and failures, the system learns to learn. }
    Approaches include:
    \begin{itemize}
        \item Unmasking: Measurement of reconstruction errors starting from a good reconstruction and iteratively impairing the reconstruction. % example on page 9 of Benno's paper
        \item Qsum heuristic: Compares the growth rates of two cumulative sums over a sequence of sentences. The sums are calculated via the deviations from the mean sentence length and the deviations of the function words.
        \item Batch means: \todo{For a series of values the variance development of the sample mean is measured while the sample size is successively increased.}
    \end{itemize}
\end{definition}

\begin{definition}
    [Unmasking]
    The idea of this meta learning approach is that with progressively omitting more and more frequent words/ most discriminating features, 
    topic specific words are excluded and thus, leaving only writing style specific words \cite{stein_intrinsic_2011}.
    After several iterations, remaining features which are not powerful enough to discriminate two documents indicate that 
    these documents originate from the same author \cite{stein_intrinsic_2011,tyo_state_2022,bevendorff_divergence_based_2020}.
    In other words: 
    Two texts are probably written by different authors if the differences between are robust to changes in the underlying feature set used to represent the documents.
    Differences can be measured using instance-based (meta) classification via cross-validation accuracy \cite{koppel_authorship_2011,bevendorff_generalizing_2019,bevendorff_divergence_based_2020,potthast_stylometric_2018}, 
    creating a performance degradation curve \cite{tyo_state_2022}.
    An \ac{svm} is trained to classify the degradation curve to determine whether two text originated from the same author \cite{tyo_state_2022,bevendorff_generalizing_2019}.
    Cf. \cite{bevendorff_divergence_based_2020} Chapt. 2 for a detailed algorithm.
    Steep decrease in the curve indicates that the two texts are similar, and thus, written by the same authors \cite{potthast_stylometric_2018}.
    Provided that the unseen text is very large, this method can handle small open candidate sets \cite{koppel_authorship_2011}.
    % koppel_determining_2014, pg. 1 + bevendorff_generalizing_2019 chap. 3.1 incl. algo: based on text chunks of length >= 500 words each
    \citet{koppel_determining_2014,bevendorff_generalizing_2019} claim that effective unmasking requires input documents to be large 
    (i.e. > 10000 words~\cite{koppel_determining_2014}, book-length~\cite{bevendorff_generalizing_2019}, $\geq$ 5000 words (500 words per chunk) \cite{bevendorff_divergence_based_2020}).
    Otherwise the training set becomes too sparse and no descriptive curves can be generated \cite{bevendorff_generalizing_2019,bevendorff_divergence_based_2020}.
\end{definition}

\begin{definition}
    [Stop words vs. function words]
    Function words are the most common words (articles, prepositions, pronouns, etc.) 
    like "while", "upon", "though", "were", "your" \cite{stamatatos_survey_2009,elmanarelbouanani_authorship_2014}.
    Most function words are stop words, but not all stop words are function words \cite{stein_intrinsic_2011}.
    \citet{elmanarelbouanani_authorship_2014} state that researchers use between 150 and 675 function words as features.
    \citet{abbasi_writeprints_2008} state that function words are highly effective discriminators of authorship, since 
    the usage variations of such words are strong reflection of stylistic choices.
\end{definition}

\begin{definition}
    [One-class classification]
    A classification problem where the classifier is trained on samples of a single class.
    If counterexamples, i.e. so-called outliers, are available, they are usually not considered to be representative of \textit{non-target class}.
    Hence, the classifier has to learn the concept of the target class in the absence of discriminating features.
    Examples of one-class classification are intrinsic plagiarism analysis and \ac{av}.
    Approaches to one-class classification fall into the following categories \cite{stein_intrinsic_2011}:
    \begin{itemize}
        \item One-class density estimation, e.g., Naive Bayes
        \item One-class boundary estimation
        \item One-class reconstruction
    \end{itemize}
\end{definition}

\begin{definition}
    [Open-set classification]
    The true author is not necessarily included in the set of candidate authors \cite{stamatatos_survey_2009,barlas_cross_domain_2020}.
\end{definition}

\begin{definition}
    [Closed-set classification]
    The true author is one necessarily one of the candidate authors \cite{stamatatos_survey_2009,koppel_authorship_2011,barlas_cross_domain_2020,boenninghoff_o2d2_2021}.
    In other words: The set of all possible author classes is known a priori.
    Hence, closed-set problems can use supervised or unsupervised classification techniques \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Supervised techniques]
    Supervised techniques for stylometric analysis require (author-)class labels for categorization.
    Examples include \acp{svm}, \acp{nn}, decision trees, and linear discriminant analysis.
    \acp{svm} are very common in authorship analysis due to their robustness \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Unsupervised techniques]
    Unsupervised techniques make categorizations with no prior knowledge of author classes.
    Examples include \ac{pca} and cluster analysis.
    \ac{pca} has been used in previous authorship studies due to its ability to 
    capture essential variance across large number of features in a reduced dimensionality \cite{abbasi_writeprints_2008}.
\end{definition}

\begin{definition}
    [Covariate shift]
    The distribution of neural stylometric features changes between training and test set due to, for instance, topic variability \cite{boenninghoff_o2d2_2021}.
\end{definition}

\begin{definition}
    [n-gram]
    $n$ contiguous words also known as word collocations. \todo{cite, reference?\cite{koppel_authorship_2011}?}
    n-grams are no stylometric features \cite{altakrori_topic_2021}.
    % Quelle Martin Potthast Gespräch 19.05.2025:
    Tri-grams are commonly used in stylistic analysis, due to their ability to capture inflections, % Flexion/ Beugung in Deutsch
    morphemes, %  smallest meaningful constituents within a linguistic expression and particularly within a word
    and other syntactic structures for Germanic languages.

\end{definition}

\begin{definition}
    [Space free n-gram]
    Removing spaces from the $n$-gram reduces the number of $n$-grams.
    \citet{koppel_authorship_2011} use these definitions:
    \begin{enumerate}
        \item a string of $n$ characters that not include spaces
        \item a string of less than $n$ characters that is surrounded by spaces
    \end{enumerate}
\end{definition}

\begin{definition}
    [Domain shift]
    Systematic statistical differences between the training and test sets \cite{tyo_state_2022}.
    These differences include:
    \begin{itemize}
        \item datasets are not identically distributed
        \item test set contains novel topics $\times_t$
        \item test set contains novel authors $\times_a$
        \item test set contains novel genres $\times_g$
    \end{itemize}
\end{definition}

\begin{definition}
    [Topic-confusion]
    In this setting, all topics appear in both training and test set. 
    However, the topics of the texts for each author changes in the test set, 
    i.e. author-topic configuration is switched between training and testing.
    For example, in the training set, the author $A_1$ writes about topic $T_1$, author $A_2$ writes about topic $T_2$ 
    and in the test set, 
    the author $A_1$ writes about topic $T_2$ while author $A_2$ writes about topic $T_1$ \cite{tyo_state_2022,altakrori_topic_2021}.
    Intuitive, the more a feature is influenced by the topic of document to identify its author, 
    the more confusion it will be to the classifier when the topic-author combination is switched, which will lead to performance deterioration \cite{altakrori_topic_2021}.
\end{definition}

\begin{definition}
    [text distortion]
    This domain-adversial method substitutes out-of-vocaublary items with asterisks $*$ \cite{tyo_state_2022}.
    Its goal is to reduce domain-specific information \cite{bischoff_importance_2020}.
    Distortion algorithms include \cite{bischoff_importance_2020}:
    \begin{itemize}
        \item Replacing tokens with multiple asterisks
        \item Replacing tokens with single asterisks
        \item Retaining only exterior characters of words in a dictionary
        \item Retaining the last two characters
    \end{itemize}
\end{definition}

\begin{definition}
    [Imposter method]
    This method extends the ngram-unmasking method, i.e. iteratively omitting most influencely features (repeated feature subsampling \cite{koppel_determining_2014})
    from a trained classifier and classifying the accuracy drop.
    It takes score of how often an author is predicted after each feature-elimination step.
    The final prediction is made based on this score \cite{tyo_state_2022}.
\end{definition}


\begin{definition}
    [Hard Negative Mining]
    This method updates the model during training only with the most difficult examples in each batch.
    In the \ac{aa} context, difficult is defined as the most similar two texts from different authors, 
    which makes the decision the most difficult.
    \citet{tyo_state_2022} claim that the \ac{av} setting is strictly easier since 
    it most compare to only a single text.
    Due to the fact, that the most difficult example is model-dependent, \ac{av} problems can be made harder 
    but they can not exist of exactly the hardest negatives.
\end{definition}

\begin{definition}
    [Domain]
    The domain include topic, genre, register, idiolect, time period etc. \cite{bischoff_importance_2020}.
\end{definition}
  
\begin{definition}
    [Domain variables]
    These include topic, genre and language \cite{bischoff_importance_2020}.
\end{definition}

\begin{definition}
    [Style transfer]
    Translation or rather paraphrasing a text from a source style to a desired target style.
    Two major problems include the lack of large-scale parallel training data (i.e., texts written in both styles), 
    and the lack of reliable evaluation metric (i.e. assessment by humans) \cite{bischoff_importance_2020}.
\end{definition}

\begin{definition}
    [Author obfuscation]
    Task of paraphrasing a text to render an author's style imperceptible.
    Usually, another text from the author is used as a reference for style similarity \cite{bischoff_importance_2020}.
    In other words: It is the adversarial task of preventing successful verification by altering the text's style so that 
    it no longer resembles the original author's style \cite{bevendorff_divergence_based_2020}.
\end{definition}

\begin{definition}
    [within-domain]
    Experiments with P=Q.
    Hence, it is necessary to ensure all texts are mutually from the same domain \cite{bischoff_importance_2020}.
    \begin{table}[]
        \centering
        \caption{Typical scheme $S_1$ for \ac{aa} problem instances, where A, B, are authors and P, Q domains and 
        the vertical mapping denotes which author has written in which domain. 
        For training, texts from A and B take turn; for testing, previously unseen texts from A and B are used \cite{bischoff_importance_2020}.}
        \label{tab:within_domain_aa}
        \begin{tabular}{|l|ll|ll|}
        \hline
        \textbf{Scheme $S_1$} & \multicolumn{2}{l|}{\textbf{training}} & \multicolumn{2}{l|}{\textbf{testing}} \\ \hline
        \textbf{authors} & \multicolumn{1}{l|}{A} & B & \multicolumn{1}{l|}{A} & B \\ \hline
        \textbf{domains} & \multicolumn{1}{l|}{P} & Q & \multicolumn{1}{l|}{P} & Q \\ \hline
        \end{tabular}%
    \end{table}
\end{definition}

\begin{definition}
    [Domain swapping]
    Experiments with P$\neq$Q \cite{bischoff_importance_2020}.
    \begin{table}[]
        \centering
        \caption{Domain-swapping scheme $S_2$ for \ac{aa} problem instances, where A, B, are authors and P, Q domains and 
        the vertical mapping denotes which author has written in which domain. 
        For training, texts from A and B take turn; for testing, previously unseen texts from A and B are used \cite{bischoff_importance_2020}.}
        \label{tab:within_domain_aa}
        \begin{tabular}{|l|ll|ll|}
        \hline
        \textbf{Scheme $S_2$} & \multicolumn{2}{l|}{\textbf{training}} & \multicolumn{2}{l|}{\textbf{testing}} \\ \hline
        \textbf{authors} & \multicolumn{1}{l|}{A} & B & \multicolumn{1}{l|}{A} & B \\ \hline
        \textbf{domains} & \multicolumn{1}{l|}{P} & Q & \multicolumn{1}{l|}{Q} & P \\ \hline
        \end{tabular}%
    \end{table}
    There are two kinds of domain swapping:
    \begin{itemize}
        \item \textbf{Zero-knowledge swapping}: Maximizes the potential for confusion during training, 
        since the models never see an author in writing in the other author's respective fandom.
        This approach aggravates adversarial training, since it needs domain knowledge to be effective.
        \item \textbf{High-imbalance swapping}: Imbalance is swapped between the training and test set. 
        This is an approximation of the zero-knowledge swapping, while still allowing adversarial learning.
    \end{itemize}
\end{definition}

\begin{definition}
    [train-test-validation split]
    \citet{bischoff_importance_2020,altakrori_topic_2021,boenninghoff_o2d2_2021} train their model on a selection of the dataset (i.e. training set), 
    optimize the model's hyperparameters on a second disjoint selection of the dataset (i.e. validation set),
    and evaluate the model on a third disjoint selection of the dataset (i.e. test set).
    \citet{bischoff_importance_2020} ensure that there is no data leakage between the training, validation and test sets 
    (i.e. prevent parts of one fanfiction being in more than one of the data splits).
    \citet{altakrori_topic_2021} ensure the classifier to be trained has no access to any information about the setup 
    (topic confusion: group configuration or topic labels).
\end{definition}

\begin{definition}
    [Cross-domain]
    Texts of known authorship (training set) differ from texts of disputed authorship (test set) 
    in topic (i.e. cross-topic) or genre (i.e. cross-genre) 
    \cite{barlas_cross_domain_2020}.
\end{definition}

\begin{definition}
    [Cross-topic]
    New, unseen topics are used in the testing phase \cite{altakrori_topic_2021}.
\end{definition}

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[]
    \centering
    \caption{\ac{aa} scenarios with author $i$ is shortened with $A_i$ \cite{altakrori_topic_2021}.}
    \label{tab:aa_same_topic}
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{} & \textbf{Train} & \textbf{Test} \\ \hline
    \textbf{Topic $T_1$} & $A_1, A_2$ & $A_1, A_2$ \\ \hline
    \textbf{Topic $T_2$} & $A_1, A_2$ & $A_1, A_2$ \\ \hline
    \end{tabular}%
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[]
    \centering
    \caption{\ac{aa} scenarios with author $i$ is shortened with $A_i$ \cite{altakrori_topic_2021}.}
    \label{tab:aa_cross_topic}
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{} & \textbf{Train} & \textbf{Test} \\ \hline
    \textbf{Topic $T_1$} & $A_1, A_2$ &  \\ \hline
    \textbf{Topic $T_2$} &  & $A_1, A_2$ \\ \hline
    \end{tabular}%
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[]
    \centering
    \caption{\ac{aa} scenarios with author $i$ is shortened with $A_i$ \cite{altakrori_topic_2021}.}
    \label{tab:aa_topic_confusion}
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{} & \textbf{Train} & \textbf{Test} \\ \hline
    \textbf{Topic $T_1$} & $A_1$ & $A_2$ \\ \hline
    \textbf{Topic $T_2$} & $A_2$ & $A_1$ \\ \hline
    \end{tabular}%
\end{table}