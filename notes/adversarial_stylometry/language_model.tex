\section{Language Model}
\label{sec:language_model}

Opposed to traditional vector space models, language models consider the context of a word when computing its embedding \citep{emmery_adversarial_2021}.


% BERT
\ac{bert} is a language model trained through masked language modelling and next-sentence prediction \citep{emmery_adversarial_2021}.
Hence, \citet{emmery_adversarial_2021}'s approach to substituting certain words in a text is straightforward:
The word to be substituted is masked, and the model predict the top-$k$ most likely words.
According to this approach two potential shortcomings arise:
\begin{itemize}
    \item The predicted word can be semantically inconsistent to the original.
    \item A semantic shift could occur since the model considers predicted words prior to the current word at each position.
\end{itemize}
\citet{emmery_adversarial_2021} propose mitigating these shortcomings by using dropout to zero part of the weights of the internal embedding of the target/ original word.
They assume that the top-$k$ candidate words are semantically more similar to the original word than the masked suggestions.