\section{Impostor method}
\label{sec:impostor_method}

The problem to solve is the \ac{av} problem:
For two documents $X, Y$ determine if they were written by the same author.
As displayed in \autoref{fig:problem_reduction}, \citet{koppel_determining_2014} propose reducing the \ac{av} problem to the many-candidates problem.

\begin{figure}[htbp]
    \centering
    \includesvg{notes/Koppel_imposter_2014/reduction_closed_set_AV_to_open_set_AA}
    \caption{Reducing the \ac{av} problem to the many-candidates problem.}
    \label{fig:problem_reduction}
\end{figure}

This method produces a set of \textit{impostor} documents.
Then, \citet{koppel_determining_2014} determine whether $X$ is sufficiently more similar to $Y$ than to the impostor documents.
There are multiple important settings:
\begin{itemize}
    \item Proper methods to select the impostor documents.
    \item Proper methods to measure the similarity between documents.
\end{itemize}
Similar to unmasking, \citet{koppel_determining_2014} repeatedly select random subsets of features that serve as the basis for comparing documents.
If a documents $Y$ is more similar to document $X$ than any other document for many feature subsets, 
it is likely that $X$ and $Y$ are by the same author.
% FIXME: autoref doesn't know lst 
The algorithmic approach is displayed in \autoref{alg:impostor_algo}.
\citet{koppel_determining_2014} state that k=100 iterations are sufficient.
The threshold $\sigma^*$ varies the recall-precision tradeoff.
\citet{koppel_determining_2014} claim that the imposter method obtains strong results even for documents with no more than 500 words.
Moreover, they highlight the similarity between the impostor method and an ensemble of classifiers learning different subset of features.
% TODO: two paragraphs below conflicting? cf. koppel_determining_2014 pg. 181, 182
Furthermore, the performance of the method improves as the number of candidate author diminishes.
In an open-set scenario, fewer candidate authors makes the problem more difficult for the impostor method 
since one author being consistently more similar to the text than the others candidates across multiple feature subsets is less likely in large sets of competing candidate authors.
A greater number of \imps{} reduces the number of \acp{fp} and \acp{fn}.
% cf. koppel_determining_2014 pg. 182, but conflicting with above:
% Small sets of candidate authors are more likely to generate \acp{fp} 
% while large sets may generate \acp{fn} and thus, creating a tradeoff.

\begin{algorithm}
    \caption{\imps{} Method for Author Verification}
    \label{alg:impostor_algo}
    \begin{algorithmic}[1]
    \Procedure{IsSameAuthor}{$X$, $Y$, $\sigma^*$}
        \Comment{$X$, $Y$: input documents; $\sigma^*$: decision threshold}
    
        \State Initialize $scores = \{\}$ 
    
        \ForAll{$d \in \{X, Y\}$}  
            \State $d' \gets \{X, Y\} \setminus \{d\}$ 
            \Comment{Disputed document $d'$}
            \State $\mathcal{I}_d \gets \text{GenerateImpostors}(d)$ 
            \Comment{$m$ impostor documents for candidate $d$}
    
            \State $scores[d] \gets 0$ 
    
            \For{$i = 1$ to $100$} 
                \Comment{100 random feature subsets}
                \State $F_i \gets \text{RandomSubset}(\text{Features})$ 
                \State $S \gets \{ \text{Similarity}(d', I_j \mid F_i) : I_j \in \mathcal{I}_d \cup \{d\} \}$ 
                \State $j^* \gets \arg\max_j S_j$ 
                \If{$I_{j^*} = d$} \Comment{Count times $d=$ top match}
                    \State $scores[d] \gets scores[d] + 1$ 

                \EndIf
            \EndFor
        \EndFor
    
        \State \Return $\left( \frac{scores[X] + scores[Y]}{2} > \sigma^* \right)$ 
        \Comment{Return \textbf{True} if average $> \sigma^*$}
    \EndProcedure
    \end{algorithmic}
    \end{algorithm}
    
% Tradeoff/ Risks
If we want to generate \imps{} for a document $Y$ and compare it to a document $X$, 
the \imps{} should be similar (e.g., in terms of genre) to $Y$ rather than $X$.
Otherwise, the $Y$ would never be the top match and thus, producing \acp{fn}.
Unconvincing impostor documents would lead to \acp{fp} due to the lack of similarity between $X$ and the impostor documents making $Y$ consistently the top match.

% Choice of the impostor documents 
First the $m$ most similar impostor (in terms of min-max similarity) documents are selected.
Then, $n$ random impostor documents are selected from the $m$ impostor documents.
\citet{koppel_determining_2014} found that using a selection of $n$ \imps{} rather than all $m$ impostor documents produces better results.
The approach is insensitive to $m,n$.
\citet{koppel_determining_2014} propose three options of generating the impostor documents.
\begin{itemize}
    \item Fixed
    \item On-the-fly
    \item Blogs
\end{itemize}

Fixed impostor documents can be aggregated results of random (English) Google queries.
They have not special relation to the document pair in question.

% sicher, non-reference???
On-the-fly impostor documents are generated by randomly selecting medium-frequency words from the document $Y$ (i.e.\ the \textcolor{red}{non-reference document} in \autoref{alg:impostor_algo}).
The words are then used to query Google and aggregate the top results of the respective queries. 
Hence, the impostor documents are similar to the document $Y$ in terms of content.

When using blogs as impostor documents, the impostor documents are selected from other bloggers. 
Hence, the impostor documents are similar to both documents $X,Y$ in terms of assuming $X,Y$ share a genre.
According to \citet{koppel_determining_2014}, this method produces the best results.

\citet{koppel_determining_2014} claim that similar \imps{} to the document $Y$ reduce the number of impostor documents needed to achieve a certain level of performance.
They also state that the search engine is used if no information about the input documents is available.