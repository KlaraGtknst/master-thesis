
\section{Exp.\ 1: Reproduction of Original Work}
\label{sec:reproduction_res}

Our first experiment covers the reproduction of the original results~\citep{koppel_determining_2014}.
It is noteworthy, that we do not expect exact replication since we could only reimplement the approach to our best knowledge.
Both Mr.\ Koppel and Mr.\ Winter were very forthcoming when we contacted them regarding implementation details that could help to improve our implementation.
Unfortunately, the code was no longer traceable and neither author could recall the preprocessing steps.
After consultation with Mr.\ Winter, he assured that our preprocessing steps seem reasonable.
This, however, certainly is one of the reasons why our implementation diverges from the original work.

\paragraph{Exp.\ 1(a): Varying number of \imps{}.}

For this experiment, we generated \imps{} using the \texttt{fixed} method while varying only the number of \imps{}.
\citet{koppel_determining_2014} reported results for 50, 500 and 5000 \imps{} on the \dataBlog{} dataset.
We ran the experiment for 50, 500, 5000 \imps{} on the \dataStudent{} dataset, and for 50, 500, 1000 \imps{} on the \dataBlog{} dataset.
Although we draw comparisons between their findings and ours, direct comparability remains limited, since our experiments on the \dataBlog{} dataset were constrained to a maximum of \num{1000} \imps{} rather than the \num{5000} as in the original study.
Our results for the \dataBlog{} and \dataStudent{} datasets are shown in \Cref{fig:blog_dif_n} and Appendix \ref{app:exp_student_dif_n}, respectively.

The original \impAppr{}'s recall–precision curves on the \dataBlog{} dataset demonstrate a clearer distinction between the evaluated approaches than our results.
We were unable to reproduce the exact values reported by \citet{koppel_determining_2014} (highlighted in red in \Cref{fig:blog_dif_n}). 
Our results indicate that increasing the number of \imps{} from 500 to the maximum tested has only a negligible effect on precision and recall for both datasets.

Consistent with the original findings, employing 50 \imps{} yields slightly higher effectiveness. 
However, repeating the experiment on multiple subsets of 20 samples per class for the \dataBlog{} dataset revealed that the optimal number of \imps{} varies across runs, highlighting the sample-dependent nature of the effect.

% By contrast, our experiments on the \dataStudent{} dataset  support the original conclusion that 50 \imps{} achieve superior effectivity, thereby highlighting a dataset-dependent effect.

\begin{figure}[htbp]
    \centering
    \includesvg[width=0.93\textwidth]{images/imposter/reproduction_koppel_figures/fig2/blog/roc_prec_recall_curve_fixed_r100_top100000_dif_n_imp_cleansed.svg}
    \caption[Recall-precision curves for the various sized \imp{} set sizes]{Recall-precision curves for the various sized \texttt{fixed} \imp{} set sizes on the \dataBlog{} dataset.
    The original \impAppr{}’s recall–precision curves show a clearer distinction between the evaluated configurations.
    Our results (lines) differ from the scores reported by \citet{koppel_determining_2014} (red point and cross).
    }
    \label{fig:blog_dif_n}
\end{figure}


\paragraph{Exp.\ 1(b): Varying \imp{} selection.}

Adhering to \citet{koppel_determining_2014}, we compared multiple \ac{av} methods with variants of the \impAppr{} that employ different \imp{} selection strategies in the traditional \ac{av} scenario with human-authored text pairs.
We obtained scores for the \texttt{fixed} and \texttt{on-the-fly} \imp{} selection strategies. 
The baselines introduced by \citet{koppel_determining_2014} include a \ac{svm} and unsupervised similarity based approaches.
Each class is treated once as the positive (i.e.\ reference) class, with the other serving as negative. 
In our implementation, this choice only influences score computation. 
Because we report precision–recall values across multiple thresholds rather than optimising a single threshold on a training set, no retraining is required.
While the original study reports results for the \dataBlog{} dataset only, we studied the results on both the \dataBlog{} dataset and the \dataStudent{} dataset.

% original results
The recall–precision curves reported by \citet{koppel_determining_2014}\ indicate that \texttt{fixed} \imp{} selection outperforms \texttt{on-the-fly} \imp{} selection.
In their study, the minimum recall values for the different-author class were consistently higher (approximately $0.625$ for \texttt{fixed} and $0.58$ for \texttt{on-the-fly}) than for the same-author class (approximately $0.38$ for \texttt{fixed} and $0.22$ for \texttt{on-the-fly}).
In contrast, precision values exhibited the opposite trend where all approaches achieved higher precision in the same-author setting compared to the different-author setting.

Our interpretation of the results reported by \citet{koppel_determining_2014}\ is presented in \Cref{fig:findings_original_work}.
We argue that these findings are a consequence of the nature of \ac{av} as an open-set one-class classification problem.
Because the different-author class lacks representative samples, it remains inherently ill-defined.
As a consequence, the \impAppr{} employing any of the two \imp{} selection methods tends to yield more different-author predictions than same-author predictions, producing higher recall for the different-author class and higher precision for the same-author class.

\begin{figure}[htbp]
    \centering
    \includesvg[width=\textwidth]{images/imposter/reproduction_koppel_figures/fig2/student_essays/fig2_original_findings.svg}
    \caption[Aggregating original \impAppr{} experiment results]{Results reported by \citet{koppel_determining_2014} suggest that the different\-author class is more difficult to model, leading to more different-author predictions and consequently higher recall for that class.}
    \label{fig:findings_original_work}
\end{figure}

% \textcolor{red}{TODO: figures SVC to SVM}
\begin{figure}[htbp]
  \centering
  \begin{subfigure}[b]{0.9\textwidth}
    \centering
    \includesvg[width=\linewidth]{images/imposter/reproduction_koppel_figures/fig4/blog/blog_roc_prec_recall_curve_r100_top100000_Same_Author_dif_imp_gen.svg}
    \caption{Same-author reference class. }
    \label{fig:blog_same_author}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.9\textwidth}
    \centering
    \includesvg[width=\linewidth]{images/imposter/reproduction_koppel_figures/fig4/blog/blog_roc_prec_recall_curve_r100_top100000_Different_Author_dif_imp_gen.svg}
    \caption{Different-author reference class.}
    \label{fig:blog_diff_author}
  \end{subfigure}
  \caption[Recall-precision curves for the \dataBlog{} dataset]{Recall-precision curves for the \dataBlog{} dataset. 
  (B) indicates the original baseline approaches from~\citet{koppel_determining_2014}.
  Due to API limit restrictions, the test set for \texttt{on-the-fly} was smaller, which is visible in the respective curves.
  The different-author curves deviate substantially from those reported by \citet{koppel_determining_2014}.
  }
  \label{fig:diff_imp_gen_blog}
\end{figure}

% our results
Both \citet{koppel_determining_2014}\ and our results indicate that \texttt{fixed} \imp{} selection performs best in the same-author scenario.
Beyond this agreement, however, our recall–precision curves deviate from the original findings.
In the different-author scenario, all methods except \texttt{on-the-fly} selection exhibit low precision, with \texttt{fixed} \imps{} performing worst.
Low precision corresponds to a high number of \acp{fp}, i.e.\ many same-author pairs incorrectly classified as different authors.
This outcome supports the hypothesis that the different-author class is more difficult to model.
% training on the same-author class produces systematically poor effectivity in a different-author class test scenario, as the model is not optimised for it.

Opposed to the original work of \citet{koppel_determining_2014}, our \texttt{on-the-fly} \imps{} lack difficulty.
Hence, our results display low precision in the same-author and the high precision in the different-author scenario.
Since we had to reduce the number of test samples for \texttt{on-the-fly} \imp{} selection due to API call limits, we suggest analysing this approaches' results with a grain of salt.
However, Mr.\ Winter noted that our \texttt{on-the-fly} \imp{} selection implementation seems insufficient, due to the rise of bot prevention blocking web scraping and the very limited number of API calls per month.
