\section{Exp.\ 3: Paraphrasing Chunks}
\label{sec:results_chunks}

This experiment tests the hypothesis that dividing a text into smaller chunks improves paraphrasing performance, as individual chunks typically contain fewer topics than the full text. 
We computed several paraphrasing metrics for each chunk and averaged the results over the chunks of a text.

\begin{table}[h]
\centering
\caption[Impact of the number of chunks on paraphrase measures.]{Impact of the number of chunks on syntactic and semantic paraphrase measures. 
Impact is reported as the absolute change between a single-chunk paraphrase and the maximum number of chunks. 
Bold values indicate the largest observed changes. 
Ideally, syntactic measures should be minimized, while semantic measures are maximized.}
\label{tab:impact_chunks_dataset_paraphraser}
\resizebox{\textwidth}{!}{%
\begin{tabular}{llllll}
    \toprule
\textbf{}         & \textbf{}            & \multicolumn{2}{l}{\textbf{Syntactic Measure} $\downarrow$} & \multicolumn{2}{l}{\textbf{Semantic Measure} $\uparrow$} \\
\textbf{Dataset} & \textbf{Model Type} & \textbf{\diameter}          & \textbf{$\sigma$}          & \textbf{\diameter}          & \textbf{$\sigma$}         \\
\midrule
\multirow{2}{*}{\dataBlog{}}           & one-step & 0.01  & 0.01 & -0.03 & 0.02 \\
                                & two-step & \textbf{-0.12} & 0.08 & -0.03 & 0.04 \\
\multirow{2}{*}{\dataGutenberg{}}      & one-step & 0.0   & 0.0  & -0.04 & 0.03 \\
                                & two-step & 0.0   & 0.0  & -0.01 & 0.05 \\
\multirow{2}{*}{\dataStudent{}} & one-step & 0.03  & 0.04 & 0.03  & 0.07 \\
                                & two-step & \textbf{-0.15} & 0.08 & -0.05 & 0.02 \\
                                \bottomrule
\end{tabular}%
}
\end{table}

\autoref{tab:impact_chunks_dataset_paraphraser} summarizes the effect of chunking on syntactic and semantic measures. 
For two-step paraphrasers, the difference between semantic and syntactic scores increases with the number of chunks, driven by decreasing mean average syntactic similarity for the \dataBlog{} and \dataStudent{} datasets. 
\autoref{fig:abl_chunks_blog_translation} illustrates the effect for the translation-based paraphraser on the \dataBlog{} dataset. 
On the \dataGutenberg{} dataset, chunking reduces the semantic similarity of translation-based paraphrases, while other two-step paraphrasers remain largely unaffected, resulting in minimal change to the overall mean semantic similarity. 
Interestingly, two-step approaches on the \dataPan{} dataset show a peak in syntactic measures at two chunks, a phenomenon we were unable to explain. 
As shown in \autoref{fig:abl_chunks_student_essays_llama}, chunking had negligible impact on one-step paraphrasing approaches. 
Additional visualizations are provided in the Appendix (cf. \autoref{sec:app_chunks}).

Since \ac{rouge} scores are computed on individual reference-candidate pairs, the union of sentences in candidate contains only a single text per comparison. 
Consequently, \ac{rouge}-L and \ac{rouge}-Lsum yield identical results in this setting.

In summary, increasing the number of chunks decreases syntactic diversity for two-step approaches, with only minor reductions in semantic similarity for some datasets. 
Given that processing $n$ chunks with a two-step approach requires $2n$ API calls in the best case, and that chunking has no effect on one-step paraphrases, we decided not to include chunking as a component of our paraphrasing pipeline.

\begin{figure}[htbp]
    \centering
    \includesvg[width=\textwidth]{images/paraphrasing/experiments/chunks/setup/results/Blog/Translation_metrics_plot_category_Blog.svg}
    \caption[Impact of the number of chunks on \dataBlog{} dataset.]{
    Average syntactic and semantic measures (shaded areas indicate standard deviation) for the translation-based paraphraser on the \dataBlog{} dataset. 
    Increasing the number of chunks reduces syntactic similarity.    
    }
    \label{fig:abl_chunks_blog_translation}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includesvg[width=\textwidth]{images/paraphrasing/experiments/chunks/setup/results/Student_Essays/meta-llama-3.1-8b-instruct_metrics_plot_category_Student Essays.svg}
    \caption[Impact of the number of chunks on \dataStudent{} dataset.]{Average paraphrasing measures (shaded areas indicate standard deviation) for a LLAMA-based paraphraser on the \dataStudent{} dataset. 
    One-step paraphrasing is unaffected by the number of chunks.
    }
    \label{fig:abl_chunks_student_essays_llama}
\end{figure}