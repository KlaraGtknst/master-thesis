\section{Exp.\ 3: Paraphrasing Chunks}
\label{sec:results_chunks}

This experiment tests the hypothesis that dividing a text into smaller chunks improves paraphrasing effectiveness, as individual chunks typically contain fewer topics than the full text. 
We computed several paraphrasing metrics for each chunk and averaged the results over the chunks of a text.

\begin{table}[t]
\centering
\caption[Impact of the number of chunks on paraphrase measures]{Impact of the number of chunks on syntactic and semantic paraphrase measures. 
Impact is reported as the absolute change between a single-chunk paraphrase and the maximum number of chunks (i.e.\ 5). 
Bold values indicate the largest observed changes. 
Ideally, syntactic measures should be minimised, while semantic measures are maximised.}
\label{tab:impact_chunks_dataset_paraphraser}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llrrrr@{}} % numbers should be right aligned, text left aligned
    \toprule
\textbf{}         & \textbf{}            & \multicolumn{2}{l}{\textbf{Syntactic Measure} $\downarrow$} & \multicolumn{2}{l}{\textbf{Semantic Measure} $\uparrow$} \\
\textbf{Dataset} & \textbf{Model Type} & \textbf{\diameter}          & \textbf{$\sigma$}          & \textbf{\diameter}          & \textbf{$\sigma$}         \\
\midrule
\dataBlog{}        & one-step & 0.01  & 0.01 & -0.03 & 0.02 \\
                                & two-step & \textbf{-0.12} & 0.08 & -0.03 & 0.04 \\
\dataGutenberg{}    & one-step & 0.0   & 0.0  & -0.04 & 0.03 \\
                                & two-step & 0.0   & 0.0  & -0.01 & 0.05 \\
\dataStudent{} & one-step & 0.03  & 0.04 & 0.03  & 0.07 \\
                                & two-step & \textbf{-0.15} & 0.08 & -0.05 & 0.02 \\
                                \bottomrule
\end{tabular}%
}
\end{table}

\Cref{tab:impact_chunks_dataset_paraphraser} summarises the effect of chunking on syntactic and semantic measures. 
For two-step paraphrasers, the difference between semantic and syntactic scores increases with the number of chunks, driven by decreasing mean average syntactic similarity for the \dataBlog{} and \dataStudent{} datasets. 
\Cref{fig:abl_chunks_blog_translation} illustrates the effect for the translation-based paraphraser on the \dataBlog{} dataset. 
On the \dataGutenberg{} dataset, chunking reduces the semantic similarity of translation-based paraphrases, while other two-step paraphrasers remain largely unaffected, resulting in minimal change to the overall mean semantic similarity. 
As shown in \Cref{fig:abl_chunks_student_essays_llama}, chunking had negligible impact on one-step paraphrasing approaches. 
Additional visualisations are provided in the Appendix (cf.~\Cref{sec:app_chunks}).

Since \ac{rouge} scores are computed on individual reference-candidate pairs, the union of sentences in candidate contains only a single text per comparison. 
Consequently, \ac{rouge}-L and \ac{rouge}-Lsum yield identical results in this setting.

In summary, increasing the number of chunks decreases syntactic diversity for two-step approaches, with only minor reductions in semantic similarity for some datasets. 
Given that processing $n$ chunks with a two-step approach requires $2n$ API calls in the best case, and that chunking has no effect on one-step paraphrases, we excluded chunking from our paraphrasing pipeline.

% \begin{figure}[htbp]
%     \centering
%     \includesvg[width=\textwidth]{images/paraphrasing/experiments/chunks/setup/results/Blog/Translation_metrics_plot_category_Blog.svg}
%     \caption[Impact of the number of chunks on \dataBlog{} dataset]{
%     Average syntactic and semantic measures (shaded areas indicate standard deviation) for the translation-based paraphraser on the \dataBlog{} dataset. 
%     Increasing the number of chunks reduces syntactic similarity.    
%     }
%     \label{fig:abl_chunks_blog_translation}
% \end{figure}

% \begin{figure}[htbp]
%     \centering
%     \includesvg[width=\textwidth]{images/paraphrasing/experiments/chunks/setup/results/Student_Essays/meta-llama-3.1-8b-instruct_metrics_plot_category_Student Essays.svg}
%     \caption[Impact of the number of chunks on \dataStudent{} dataset]{Average paraphrasing measures (shaded areas indicate standard deviation) for a Llama-based paraphraser on the \dataStudent{} dataset. 
%     One-step paraphrasing is unaffected by the number of chunks.
%     }
%     \label{fig:abl_chunks_student_essays_llama}
% \end{figure}

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includesvg[width=\textwidth]{images/paraphrasing/experiments/chunks/setup/results/Blog/Translation_metrics_plot_category_Blog.svg}
    \caption[Translation-based paraphraser on \dataBlog{}]{
    Translation-based paraphraser on the \dataBlog{} dataset.    
    }
    \label{fig:abl_chunks_blog_translation}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{\textwidth}
    \centering
    \includesvg[width=\textwidth]{images/paraphrasing/experiments/chunks/setup/results/Student_Essays/meta-llama-3.1-8b-instruct_metrics_plot_category_Student Essays.svg}
    \caption[Llama-based paraphraser on \dataStudent{}]{Llama-based paraphraser on the \dataStudent{} dataset.
    }
    \label{fig:abl_chunks_student_essays_llama}
  \end{subfigure}
  \caption[Effect of chunking on syntactic and semantic measures]{Average syntactic and semantic similarity measures (shaded areas indicate standard deviation) for different number of chunks.
  \Cref{fig:abl_chunks_blog_translation} shows that increasing the number of chunks reduces syntactic similarity for the translation-based paraphrases, whereas \Cref{fig:abl_chunks_student_essays_llama} demonstrates that one-step paraphrasing is largely unaffected by the number of chunks.
  }
  \label{fig:abl_chunks}
\end{figure}