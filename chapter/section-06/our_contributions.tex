\section{Exp.\ 5: Comparing Authorship Verification Methods}% in Traditional Human-Human Scenario}
\label{subsec:imp_gen_res}

We evaluate precision–recall values across different thresholds for the baseline methods, and the fixed approach proposed by \citet{koppel_determining_2014} as well as for the \ac{llm}-based \impAppr{}.
Our results indicate that the supervised baseline and our one-step paraphrasing approach produce identical outcomes.
An examination of the individual values confirms this observation, revealing identical precision–recall pairs for different thresholds.
We attribute this effect to the relatively small sample size of only 10 text pairs per class.

With respect to optimising the precision–recall trade-off, the \ac{llm}-based \impAppr{} achieve the most favourable performance with precision of $0.73$ and recall of $0.8$ at a threshold of $0.105$.
When precision is prioritised over recall, however, most remaining methods outperform these two approaches, as they achieve higher recall while maintaining the same maximum precision.
Although the definition of an optimal balance between precision and recall is application-dependent, we argue that a recall of at most $0.4$ at perfect precision is generally less informative than jointly optimising both metrics.

\begin{figure}[htbp]
    \centering
    \includesvg[width=\textwidth]{images/imposter/our_contribution/roc_prec_recall_curve_r100_top100000_Same_Author_dif_imp_gen.svg}
    \caption[Recall-precision curves for the \dataStudent{}]{Recall-precision curves for 20 samples per class of the \dataStudent{}. 
    (B)~indicates the original baseline approaches from~\citep{koppel_determining_2014}.
    }
    \label{fig:comp_naive_student}
\end{figure}

These findings contrast with our initial expectation that \ac{llm}-based \imp{} generation would achieve higher precision, but indicate that our approach performs best when precision and recall are considered equally important.
