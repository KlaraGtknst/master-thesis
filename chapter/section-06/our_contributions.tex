\section{Exp.\ 5: Comparing Authorship Verification Methods}% in Traditional Human-Human Scenario}
\label{subsec:imp_gen_res}

We evaluate precision–recall values across different thresholds for the baseline methods, and the fixed approach proposed by \citet{koppel_determining_2014} as well as for the \ac{llm}-based \impAppr{}.
Our results indicate that the supervised baseline and our one-step paraphrasing approach (Naive \ac{llm} in \autoref{fig:sem_syn_blog}) produce identical outcomes.
An examination of the individual values confirms this observation, revealing identical precision–recall pairs for different thresholds.
We attribute this effect to the relatively small sample size of only 10 text pairs.

With respect to optimizing the precision–recall trade-off, the supervised baseline and the \ac{llm}-based \impAppr{} achieve the most favourable performance at a threshold of $0.075$, and $0.32$ respectively.
When precision is prioritized over recall, however, all remaining methods outperform these two approaches, as they achieve higher recall while maintaining the same maximum precision.
Although the definition of an optimal balance between precision and recall is application-dependent, we argue that a recall of $0.4$ at perfect precision is generally less informative than jointly optimizing both metrics.

\begin{figure}[htbp]
    \centering
    \includesvg[width=\textwidth]{images/imposter/our_contribution/roc_prec_recall_curve_r100_top100000_Same_Author_dif_imp_gen.svg}
    \caption[Recall-precision curves for the \dataStudent{}.]{Recall-precision curves for the 10 samples of the \dataStudent{}. 
    One-step paraphrasers are denoted Naive \ac{llm}.
    (B)~indicates the original baseline approaches from~\citep{koppel_determining_2014}.
    }
    \label{fig:sem_syn_blog}
\end{figure}

These findings contrast with our initial expectation that \ac{llm}-based \imp{} generation would achieve higher precision, but indicate that our approach performs best when precision and recall are considered equally important.
