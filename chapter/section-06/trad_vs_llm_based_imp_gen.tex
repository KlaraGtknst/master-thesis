\section{Exp. 5: Comparing \acs{av} methods in traditional Human-Human scenario}

We want to answer the question of how our \ac{llm}-based \imp{} generation performs compared to (a) traditional \imp{} generation in the \impAppr{} and compared to (b) \acl{sota} \ac{av} methods in the traditional \ac{av} scenario.
We thus, create \textcolor{orange}{10} same- and \textcolor{orange}{10} different-author pairs from the \dataStudent{} dataset and evaluate the performance of the approaches for different thresholds.
It is noteworthy, that the dataset contains equally many naive same- and different-author pairs and hence, an approach predicting only one output will obtain an accuracy of $0.5$.

\begin{figure}[htbp]
\centering
    \includesvg[width=\linewidth]{images/AV_comparison/detection_scenarios/accuracy/student_essays_Human-Human_threshold_accs_curves_all_incl_baselines.svg}
  \caption{Accuracy curves for the class same-author across different threshold on \dataStudent{} dataset without \ac{llm} candidates. We find that \ac{llm} based approaches perform slightly above chance and better than the rest. For high thresholds, recall is not as high and thus, this approach seems not to be as bad as in other scenarios. 
  }
  \label{fig:human-human_acc}
\end{figure}

\begin{figure}[htbp]
\centering
    \includesvg[width=\linewidth]{images/AV_comparison/detection_scenarios/f1/student_essays_Human-Human_threshold_f1s_curves_all_incl_baselines.svg}
  \caption{F1 scores for the class same-author across different threshold on \dataStudent{} dataset without \ac{llm} candidates. 
  We find that \ac{llm} based approaches perform slightly better than the rest across different thresholds.
  }
  \label{fig:human-human_f1}
\end{figure}

Baseline Mirror minds performs reasonable well compared to the other approaches due to its high recall.
You may find the recall curves across different threshold attached in the Appendix in \autoref{sec:app_detection_scenarios}.
Mirror minds' paraphrases are single words, which prompt the discriminator to always predict same-author since any candidate text contains more stylistic similarity than the single-word \imps{}.
We find this approach produces many \acp{fp}.

% Since half of the test dataset contains different author pairs, thresholds bigger than $0.55$ enviably lead to the minimal accuracy possible of $0.5$.
In terms of accuracy, we find that baseline approaches perform worse than chance while traditional and \ac{llm}-based \imp{} produces better results.
In terms of F1 score, most approaches' performance greatly degrades with increasing thresholds.
Only the \ac{llm}-based approaches seem to produce steady performance across different thresholds due to their recalls values which do not fall as much as those of the other approaches.

% \begin{figure}[htbp]
%   \centering
%     \includesvg[width=\linewidth]{images/dataset/AV_comparison/student_essays_threshold_accs_curves_all_incl_baselines.svg}
%   \caption{Accuracy curves for the class same-author for different \ac{av} approaches.}
%   \label{fig:comp_av_acc}
% \end{figure}


% \begin{figure}[htbp]
%   \centering
%     \includesvg[width=\linewidth]{images/dataset/AV_comparison/student_essays_threshold_precisions_curves_all_incl_baselines.svg}
%   \caption{Precision curves for the class same-author for different \ac{av} approaches.}
%   \label{fig:comp_av_prec}
% \end{figure}