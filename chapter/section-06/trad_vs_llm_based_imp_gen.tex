\section{Exp. 5: Comparing \acs{av} methods in traditional Human-Human scenario}

We want to answer the question of how our \ac{llm}-based \imp{} generation performs compared to (a) traditional \imp{} generation in the \impAppr{} and compared to (b) \acl{sota} \ac{av} methods in the traditional \ac{av} scenario.
We thus, create \textcolor{orange}{10} same- and \textcolor{orange}{10} different-author pairs from the \dataStudent{} dataset and evaluate the performance of the approaches for different thresholds.
It is noteworthy, that the dataset contains equally many naive same- and different-author pairs and hence, an approach predicting only one output will obtain an accuracy of $0.5$.

% \begin{figure}[htbp]
% \centering
%     \includesvg[width=\linewidth]{images/AV_comparison/detection_scenarios/accuracy/student_essays_Human-Human_threshold_accs_curves_all_incl_baselines.svg}
%   \caption{Accuracy curves for the class same-author across different threshold on \dataStudent{} dataset without \ac{llm} candidates. We find that \ac{llm} based approaches perform slightly above chance and better than the rest. For high thresholds, recall is not as high and thus, this approach seems not to be as bad as in other scenarios. 
%   }
%   \label{fig:human-human_acc}
% \end{figure}

\begin{figure}[htbp]
\centering
    \includesvg[width=\linewidth]{images/AV_comparison/detection_scenarios/f1/student_essays_Human-Human_threshold_f1s_curves_all_incl_baselines.svg}
  \caption{F1 scores for the class same-author across different threshold on \dataStudent{} dataset without \ac{llm} candidates. 
  We find that \ac{llm} based approaches perform slightly better than the rest across different thresholds.
  }
  \label{fig:human-human_f1}
\end{figure}


% Since half of the test dataset contains different author pairs, thresholds bigger than $0.55$ enviably lead to the minimal accuracy possible of $0.5$.
% In terms of accuracy, we find that baseline approaches perform worse than chance while traditional and \ac{llm}-based \imp{} produces better results.
In terms of F1 score, most approaches' performance greatly degrades with increasing thresholds.
Only the \ac{llm}-based approaches seem to produce steady performance across different thresholds due to their recalls values which do not fall as much as those of the other approaches.


% In terms of accuracy, content based, fixed (for small thresholds), text length based and naive \ac{llm} perform best.
Upon further investigation of the F1 score, we find that almost all baseline methods do not work at all and even experience an extreme drop of both precision and recall at certain threshold values.
The fixed baseline works best among the baselines from \citet{koppel_determining_2014}.
The slightly more informed version considering text lengths performs slightly better.
While the choice of \imps{} is still considered uninformed, it is quite selective with its positive predictions indicated by high precision and low recall. 
Its recall values are always bigger than those of the fixed version.
We find that incorporating content similarity into the \imp{} choice does not influence the performance as both content based and fixed \imp{} generation perform similarly.
The mirror minds approach attributes almost very input pair to the same-author class and thus, has a high recall, but a precision of only around $0.5$.
You may find the recall curves across different threshold attached in the Appendix in \autoref{sec:app_detection_scenarios}.
Mirror minds' paraphrases are single words, which prompt the discriminator to always predict same-author since any candidate text contains more stylistic similarity than the single-word \imps{}.
Naive \ac{llm} based \imp{} generation performs best in terms of F1 scores, even though its precision scores are only between $0.6$ and $0.7$.
This indicates, that the generated \imps{} are still too easy and produce \acp{fp}.



% \begin{figure}[htbp]
%   \centering
%     \includesvg[width=\linewidth]{images/dataset/AV_comparison/student_essays_threshold_accs_curves_all_incl_baselines.svg}
%   \caption{Accuracy curves for the class same-author for different \ac{av} approaches.}
%   \label{fig:comp_av_acc}
% \end{figure}


% \begin{figure}[htbp]
%   \centering
%     \includesvg[width=\linewidth]{images/dataset/AV_comparison/student_essays_threshold_precisions_curves_all_incl_baselines.svg}
%   \caption{Precision curves for the class same-author for different \ac{av} approaches.}
%   \label{fig:comp_av_prec}
% \end{figure}