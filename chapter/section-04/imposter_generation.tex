\section{\imp{} Generation}
\label{sec:impostor_generation}

% good \imps{}: hard negatives
Equivalent to the original \impAppr{} by \citet{koppel_determining_2014}, we denote ideal \imp{} texts as hard negatives.
In other words, texts that are not authored by the candidate author, but are difficult to distinguish from the candidate author's texts.
Note that the quality of the \imps{} directly contributes to the performance of the model, 
since easy \imps{} lead to \acp{fp} and too difficult ones to \acp{fn}.

\subsubsection{Traditional \imp{} Generation}
\label{subsubsec:traditional_impostor_generation}

To assess the quality of our \impAppr{} implementation, we first reimplement the original \impAppr{} by \citet{koppel_determining_2014}.
The parameters are set to the original default values.


\subsubsection{Novel \imp{} Generation}
\label{subsubsec:novel_impostor_generation}
% obstacles for \imp{} generation in the past
The traditional generation techniques outlined by \citet{koppel_determining_2014} faced difficulties in controlling essential factors such as text topic or genre.
Since authorial style heavily depends on these factors, traditional \imps{} can differ a lot from the candidate text.
% model process of original text generation
The ideal generation technique would model the process of the original text generation, 
i.e. among others, the author's task, and references.
Hence, all external influential factors are specified to match the original conditions.
Unfortunately, due to the nature of this task 
(i.e. requirement of \ac{av} is often linked to a lack of information of the author either due to death in the case of literary texts or 
due to unwillingness of cooperation in case of plagiarism), this information is in most cases not available.
% heuristics: paraphrase
With \acp{llm} it is possible attempt to control external factors and 
as a heuristic to modelling the generation process, paraphrase the original text.
% lack of definition of paraphrase
Due to the lack of a universal definition of paraphrases~\citep{gohsen_task_oriented_2024}, the following criteria are used to determine the quality of the generated paraphrases:
% our criteria for good paraphrases
\begin{itemize}
    \item The generated text should belong to the same topic, genre and exhibit the same tone (\textcolor{red}{=tone???}) as the original text.
    \item The semantic information may differ (i.e. hallucination is allowed).
    \item The generated text should be different to the original text in terms of style, i.e. wording and sentence structure (i.e. syntactic similarity). \textcolor{red}{threshold to exclude near-duplicate paraphrases~\citep{gohsen_captions_2023}?}
\end{itemize}


\citet{ayele_overview_2024,bevendorff_overview_2024} collected articles of major 2021 US news from Google News (Pan AI News 2021 \citep{bevendorff_overview_2024}).
They chose this time period since it predates the release of GPT-3.5 \citep{bevendorff_overview_2024,ayele_overview_2024}.
As a consequence, they claim that their dataset is most likely human-authored.
% artificial texts
Next, they used GPT-4-Turbo to create bullet-point summaries of the articles \citep{bevendorff_overview_2024,ayele_overview_2024}. 
According to \citet{bevendorff_overview_2024}, the prompt used to generate the summaries in 2021 was:
\begin{quote}
    \textit{Summarize the following text in five to six short bullet points and give an overall description
    of the genre and tone of the text.}
\end{quote}
% in JSON format:
Moreover, they extracted the article's type (nine classes), target audience (three classes), the author's political stance (three classes), the article's dateline, 
and the names and functions of directly quoted spokespersons, if any \citep{bevendorff_overview_2024}.
Based on these summaries, 15 \acp{llm}-generated newspaper articles \citep{ayele_overview_2024}.
They were prompted to assume the role of the journalist describes by the additional information extracted from the original texts \citep{bevendorff_overview_2024}.


% prompting
The quality of \ac{llm} generated text depends on the quality of prompt~\citep{Wu_ODD_challenges_2025}.
There are multiple popular prompting approaches, such as few-shot prompt~\citep{brown_few_shot_prompting_2020}, combining prompt, Chain of Thought~\citep{Wei_CoT_2022}, zero-shot Chain of Thought~\citep{kojima_zeroshot_2022}.

% Notes
According to \citet{gohsen_task_oriented_2024}, there are two perspectives to paraphrasing: 
Lexical (i.e. changes at word level) and syntactic (i.e. changes at syntactic level).
Paraphrase types can be classified into surface and semantic level. Finer levels are outlined in \citep{gohsen_task_oriented_2024}.

Popular paraphrase categories include \citep{fu_learning_2024}:
\begin{itemize}
    \item Top-level classification perspective: 
        \begin{itemize}
            \item Lexicon-based changes
            \item Morphology-based changes
            \item others
        \end{itemize}
    \item Second-level classification perspective:
        \begin{itemize}
            \item Change of format
            \item Semantic-based
            \item Change of order
        \end{itemize}
\end{itemize}

\citet{zhou_paraphrase_2025} (pg. 3, tab.1, and examples afterwards) define a topology of paraphrase types:
\begin{itemize}
    \item Morphology based: inflection changes (e.g. singular to plural), derivation changes (e.g. adjective to verb), functional word substitution (e.g. this to that).
    \item Lexicon based: Same polarity substitution (e.g. synonym), opposite polarity substitution (e.g. antonym), converse substitution (e.g. opposite view point), spelling changes, synthetic/ analytic substitution, relational substitution
    \item Syntax based: Negation switching (i.e. other negation), diathesis alternation (e.g. change position of verb), etc.
    \item Discourse based: Indirect/direct substitutions, sentence modality changes, punctuation changes, etc.
    \item Other changes: Change of order, change of format, etc.
\end{itemize}

\citet{zhou_paraphrase_2021} claim it is difficult to control the style of generated paraphrases.

Another approach to paraphrasing is back-translation, which may limit diversity \citep{zhou_paraphrase_2025}.
