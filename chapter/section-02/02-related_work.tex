\label{chap:related_work}
\chapter{Related Work}

% where does my work fit in literetaure?
% why does my work matter?
% what gap is addressed by my work?

% start with classical, then recent and then my own work

% AV, AA & established approaches
\ac{aa} and \ac{av} are persistent problems in computational linguistics, with roots in stylometry dating back to the \nth{19} century. 
Early approaches were based on word length frequencies, with the aim of resolving disputes over literary authorship~\citep{neal_surveying_2018,stamatatos_survey_2009}.
Today, \ac{aa} and \ac{av} are applied in a wide range of contexts from plagiarism detection~\citep{stein_intrinsic_2011} to author profiling. 
Despite decades of progress, several core challenges persist: 
Application of models in cross-domain settings, short or inconsistent texts, large candidate sets where the true author may not even be present. 
These challenges have motivated successive methodological innovations, which this section reviews.

% Stylometry and Classical Approaches
Starting with Mosteller and Wallace (1964), numerous stylometric features have been proposed. 
Ranging from writeprints, a set of lexical, syntactic and structural text features~\citep{abbasi_writeprints_2008} to function words~\citep{abbasi_writeprints_2008} and character n-grams.
Both function words and n-grams have proven especially effective~\citep{tyo_state_2022,altakrori_topic_2021,koppel_authorship_2011}, and writeprints has functioned as basis for other approaches~\citep{weerasinghe_feature_vector_difference_2021}. 

% cross-domain
Studies~\citep{stamatatos_survey_2009,barlas_cross_domain_2020} have shown that character, function word and \ac{pos} n-grams are more topic-invariant than other stylometric features.
Still, \citet{bischoff_importance_2020} claim that frequent function words have a high correlation with topics.
Not only are many traditional stylometric features are sensitive to domain variation, but \citet{rivera_soto_learning_2021} find that even neural authorship models perform poor in \ac{ood} domains.

Compression-based \ac{av} methods estimate similarity through compressibility, bypassing the need for explicit features. 
The difference of the compressed files calculates the cross-entropy between the two texts.
Notable distance measures, such as the Normalized Compression Distance (NCD)~\citep{elmanarelbouanani_authorship_2014}, or the Compression-Based Classification (CBC)~\citep{bevendorff_divergence_based_2020,bevendorff_overview_2024}, rely on compression algorithms such as PPM, LZW, and GZIP. 
The central intuition is that if two texts are authored by the same individual, their concatenation will compress more efficiently than unrelated texts. 
While conceptually elegant, compression methods tend to be computationally expensive, slow and less effective on large datasets~\citep{tyo_state_2022,neal_surveying_2018}. 

%% Meta learning and Unmasking
The unmasking approach reframes \ac{av} as a meta-learning problem. 
Instead of focusing on absolute similarity, unmasking iteratively removes the most discriminative features between two documents and observes how quickly classification accuracy degrades. 
If the texts are by the same author, performance collapses rapidly under feature removal and if not, accuracy remains relatively stable~\citep{koppel_authorship_2004}. 
Unmasking has been empirically effective, particularly on long documents such as novels~\citep{koppel_authorship_2011}. 
Its main drawback, however, is its dependence on large text volumes~\citep{koppel_determining_2014,bevendorff_generalizing_2019}.

Subsequent work~\citep{bevendorff_generalizing_2019,bevendorff_divergence_based_2020} has attempted to generalize unmasking to shorter texts by creating chunks by oversampling words in a bootstrap aggregating manner. 
Real-world applications such as plagiarism detection~\citep{stein_intrinsic_2011}, or pre-filtering hyperpartisan news from mainstream news~\citep{potthast_stylometric_2018} include the unmasking approach into their architecture.

% PAN metrics: F0.5u, Brier, C@1: tyo_state_2022

%% Impostor Method and Open-Set Identification
In the \impAppr{}, \citet{koppel_determining_2014} reduce the open-set \ac{av} problem to an open-set \ac{aa} problem.
They denote the latter many-candidates problem. 
Unlike closed-set attribution, where the true author is guaranteed to be among the candidates, open-set scenarios require distinguishing not only between multiple authors but also between "in-set" and "out-of-set" cases. 
The \ac{av} problem is reduced to the many-candidates problem via adding so-called impostor texts to the candidates pool. 
Instead of relying on fixed feature sets, it repeatedly samples random subsets of features and compares the target text against both candidate authors and a set of unrelated \imps{}. 
By aggregating many such trials, the method estimates whether the candidate consistently outperforms the \imps{} across varying conditions~\citep{koppel_determining_2014}. 
The method's effectiveness depends heavily on the relevance of available impostor texts. 
This dependency motivates the use of synthetic \imps{} generated by \acp{llm}, which allow for better control over confounders.

%% LLM-Based Authorship and Detection
Recent advances in \acp{llm} have reshaped the landscape of \ac{av}. 
The emergence of \ac{ai}-generated text introduces both a novel adversary and a valuable methodological resources.
Detecting \ac{ai} generated text can be regarded as a special case of \ac{av}, where the author is a generative model~\citep{bevendorff_overview_2024}. 
Reflecting this shift, the \ac{pan} 2024 shared task "Voight-Kampff" focused on generative \ac{ai} detection, challenging participants to develop systems capable of distinguishing between human and machine-authored texts~\citep{bevendorff_overview_2024,ayele_overview_2024}.
\citet{llm_detection_av_2025} observe that, although current \ac{llm}-generated texts still exhibit detectable differences from human writing, such differences are expected to diminish as models continue to improve.
At the same time, \acp{llm} can serve as discriminators~\citep{futrzynski_pairwise_2021} or tools for augmenting \ac{av} methods, for instance through text generation, or paraphrasing~\citep{mao_raidar_2024,baradia_mirror_2025}.
Since text distortion has previously proven effective in cross-domain scenarios~\citep{bischoff_importance_2020}, \acp{llm} appear particularly promising as generators of controlled distortions in \ac{av} research.

\ac{llm} detection methods can be grouped into metric-based approaches, fine-tuned classifiers, and watermarking. 
Among these, DetectGPT is influential example for metric-based approach~\citep{wang_stumbling_2024}.
DetectGPT assumes that model-generated text corresponds to regions of high model log probability. 
By perturbing candidate texts and rescoring them, the method measures the difference of their respective probabilities.
If it is near zero, the text is likely human authored~\citep{mitchell_detectgpt_2023}. 
While powerful, DetectGPT is limited by its white-box scenarios (access to model probabilities) and is vulnerable to paraphrasing or detecting unseen models~\citep{Wu_ODD_challenges_2025}.

Other detection methods also make use of rewriting. 
Paraphrases can be generated through rule-based or thesaurus-driven substitutions, by means of monolingual machine translation~\citep{zhou_paraphrase_2021}, or by explicitly prompting generative \acp{ai} such as T5 or GPT models~\citep{kurt_pehlivanoglu_comparative_2024}.
RAIDAR, for instance, generates perturbed versions of a text using paraphrasing and compares edit distances~\citep{mao_raidar_2024}, while Mirror Minds employs paraphrasing combined with syntactic similarity metrics such as BLEU and METEOR~\citep{baradia_mirror_2025}. 
%%% compared to our work: RAIDAR
%%%% generation of texts during inference
Both approaches are similar to our work in that they use \acp{llm} to generate texts during inference.
We do not fine-tune an \ac{llm} for paraphrasing but use off-the-shelf models (like RAIDAR).
%%%% similarity measure
All these approaches compute the similarity of the original text and the generated text.
However, we do not use edit distance, BLEU or METEOR as similarity measure, nor do we compare directly on paraphrase-level (i.e. BLEU calculates n-gram overlap) but construct our own frequency-based n-gram vectors input vector similarity metrics.
%%% limitations
These approaches are unable to detect which \ac{llm} generated the text.


% Paraphrasing and Evaluation Metrics
Paraphrasing undermines detectors while also offering methodological utility. 
Systems like DIPPER~\citep{Krishna_dipper_2023} demonstrate how adversarial rewriting can bypass detection. 
At the same time, paraphrasing has been leveraged as a tool for generating stylistic variants~\citep{mao_raidar_2024,baradia_mirror_2025}.

Evaluating paraphrases remains an open challenge. 
Paraphrases evaluation can include dimensions of readability, complexity and grade level~\citep{Thomas_cross_topic_24}.
% They use Textstat, a Python library that helps extract statistics from text.
Traditional metrics such as BLEU~\citep{papineni_bleu_2001}, ROUGE~\citep{lin_rouge_2004}, METEOR~\citep{banerjee_METEOR_2005}, and GLEU~\citep{kurt_pehlivanoglu_comparative_2024} capture n-gram overlap but often fail to reflect semantic adequacy. 
Embedding-based metrics such as BERTScore~\citep{hanna_fine_grained_2021} and Word Mover's Distance~\citep{gohsen_captions_2023} offer more robust semantic similarity estimates, while human evaluation remains the gold standard~\citep{zhou_paraphrase_2021}. 
Despite this, no consensus exists on the best metric for evaluating paraphrasing. 
This uncertainty motivates further exploration of similarity measures for evaluating paraphrases.



% % LLM detection using generative models
% %% AA against LLMs

% \citet{uchendu_authorship_2020} identified three authorship tasks essential for fighting fraudulent activities:
% (1) Given two texts $t_1$ and $t_2$, determine whether they were produced by the same method (i.e. human author or a specific \ac{nlg} method).
% (2) Given a text $t$, determine whether it was human authored or machine generated (Turing Test).
% (3) Given a text $t$, find its author among $k+1$ candidates, which consists of one human and $k$ machines.

% %%% compared to our work
% In the following, we consider (1) \ac{av}, (2) classical \ac{llm} detection, and (3) closed-set \ac{aa}.
% Our approach differs from the work of \citet{uchendu_authorship_2020} in that our candidates (i.e. \imps{}) do not include a human author (3), 
% but only \acp{llm}.
% Moreover, we use different classifiers originally designed for \ac{av}, rather than \ac{aa}.



% %% LLM rewrite LLM texts less than human texts (no AA, but edit distance hypothesis)
% RAIDAR~\citep{mao_raidar_2024} builds upon the invariance property of \acp{llm}, 
% which states that prompting an \ac{llm} to rewrite a machine generated text will introduce little change.
% They motivate this by the observation that (different) autoregressive models produce similar patterns and thus, 
% consider texts generated by (different) \acp{llm} as high quality that do not require rewriting.
% Change is measured by the edit distance between the original text and the rewritten text. 
% \citet{mao_raidar_2024} propose using an edit distance based on the Levenshtein distance or \ac{bow} representations.
% RAIDAR operates on character level rather than using deep neural network features, and it does not require the original generating model for classification. 
% Classification is carried out by comparing the edit distance of the original text and the rewritten text to a threshold.


% %% LLMDet: Proxy to perplexity (problem: requires access to the LLM to build the dictionary)
% Perplexity is a reliable statistical metric for attributing texts to \acp{llm}~\citep{zhang_llmdet_2023}.
% Unfortunately, perplexity requires access to \acp{llm}' parameters (i.e., white-box detection).
% \citet{wu_llmdet_2023} propose LLMDet, a method that uses a proxy to perplexity, 
% where a dictionary of frequent n-gram (frequent among $n$ randomly prompted generated texts per \ac{llm}) 
% next token probabilities is pre-computed (i.e. requiring access to the \ac{llm}), 
% and is subsequently used during inference to approximate perplexity by replacing $x_{<i}$ in $p(x_i | x_{<i})$ with an n-gram.
% Since the construction of the dictionary requires access to the \ac{llm}, LLMDet requires contribution of the closed-source model owners.
% The disputed text is tokenized and the proxy perplexity is calculated for each model and thus, constructing a proxy perplexity vector.
% This vector is input to a trained classifier.
% %%% compared to our work
% Proxy perplexity could be used as a baseline for our approach, though it requires access to the \ac{llm} and is thus not applicable in our case.

%% AV/ AA via LLMs
