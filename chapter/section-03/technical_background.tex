\section{Technical Background}

This section outlines the \ac{ml} principles and paradigms that underpin modern authorship analysis. 
We first introduce the main classification concepts relevant to \ac{av}. 
We then discuss training and evaluation practices, including domain shift scenarios. 
Finally, we present the principal categories of authorship analysis methods.

\subsection{\acl{ml} Principles}

\ac{aa} tasks are conventionally formulated as classification problems, where the objective is to attribute an anonymous text to one of a set of candidate authors. 
Unlike regression, which estimates a continuous value, classification yields a discrete label corresponding to the author’s identity.

\paragraph{Closed- vs. open-set classification.} 
In a closed-set scenario, the true author is guaranteed to be among the candidate set~\citep{stamatatos_survey_2009,koppel_authorship_2011,barlas_cross_domain_2020,boenninghoff_o2d2_2021,neal_surveying_2018}. 
In contrast, open-set classification acknowledges that the author of a disputed document may not belong to the candidate set~\citep{stamatatos_survey_2009,barlas_cross_domain_2020,neal_surveying_2018}. 

\paragraph{One-class classification.} 
In some cases, training data is available for only a single class, and the task is to decide whether a new sample belongs to this class.
If counterexamples, i.e. so-called outliers, are available, they are usually not considered to be representative of non-target class. 
This is formalized as one-class classification, where the model learns the characteristics of the target class without reliable counterexamples~\citep{stein_intrinsic_2011,koppel_authorship_2004}.

\paragraph{Multi-class classification.} 
The standard formulation involves multiple authors, each represented by several training texts. 
Here, the challenge is to discriminate among a large and often imbalanced set of classes~\citep{stamatatos_survey_2009,koppel_authorship_2004,elmanarelbouanani_authorship_2014} .


\subsection{Training and Testing}

Models are typically trained on one portion of the data (training set), tuned on another (validation set), and evaluated on a disjoint partition (test set). 
Any overlap between these partitions constitutes data leakage and invalidates the results~\citep{bischoff_importance_2020,altakrori_topic_2021,boenninghoff_o2d2_2021}. 

A major challenge in stylometry is covariate shift, i.e., a mismatch between the distribution of training and test data. 
This often arises from topic variability~\citep{boenninghoff_o2d2_2021}. 
Two common evaluation settings are:
\begin{itemize}
    \item \textbf{Cross-topic attribution}, where models trained on one set of topics are tested on previously unseen topics~\citep{altakrori_topic_2021}.  
    \item \textbf{Cross-domain attribution}, where training and test texts differ in topic or genre~\citep{barlas_cross_domain_2020}.  
\end{itemize}

\paragraph{Supervised vs. unsupervised learning.}  
Supervised methods require labelled training data and include classifiers such as \acp{svm}, decision trees, \acp{nn}, and linear discriminant analysis. 
\acp{svm} are particularly common in authorship analysis due to their robustness. 
Unsupervised methods do not rely on labels.
Clustering techniques or \ac{pca} have been used to uncover latent stylistic patterns or to reduce feature dimensionality~\citep{abbasi_writeprints_2008}.


\subsection{Authorship Analysis Methods}
\label{subsec:attribution_methods}

Approaches to authorship analysis can be grouped into three families~\citep{stamatatos_survey_2009}:

\paragraph{Profile-based methods.} 
All training texts of an author are concatenated into a single profile, from which a cumulative feature representation is extracted. 
This approach is effective when only short texts are available.
Profile-based methods ignore intra-author variation~\citep{stamatatos_survey_2009,elmanarelbouanani_authorship_2014,neal_surveying_2018}.  

\paragraph{Instance-based methods.} 
Here, each training text is treated as a separate instance of the author's style. 
This allows models to capture intra-author variability~\citep{stamatatos_survey_2009,altakrori_topic_2021,elmanarelbouanani_authorship_2014,neal_surveying_2018}.  

\paragraph{Hybrid methods.} 
Hybrid approaches combine both paradigms by representing texts individually while aggregating author profiles through feature-wise averages computed over an author’s texts~\citep{stamatatos_survey_2009}. 
