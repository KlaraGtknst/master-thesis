\subsection{Dataset}
\label{subsec:dataset}

\subsubsection{Original Data}
Due to this approach extending the original imposter approach by \citet{koppel_determining_2014}, 
we first use original data to establish the feasibility and reproducibility of the original approach. 
\citet{koppel_determining_2014} used \dataBlog{} and the \dataStudent{} dataset.
Unfortunately, after contacting M. Koppel and J. W. Pennebaker, the \dataStudent{} dataset could not be obtained.
For establishing a baseline for the imposter approach, we only use the \dataBlog{} dataset.

\subsubsection{Additional Data}
To extend our test scenario for the imposter approach, we opted to find an additional dataset that fulfilled the following criteria:
\begin{itemize}
    \item controlled confounders (e.g. genre, topic)
    \item undisputed authorship 
    
\end{itemize}

We found that both the \dataPan{} and \dataGutenberg{} datasets are suitable candidates.
The statistical properties of the datasets are shown in \autoref{tab:data_stats}.

\begin{table}[h]
\centering\small
\caption{Statistics of preprocessed datasets \dataPan{}, \dataBlog{} and \dataGutenberg{}.}
\label{tab:data_stats}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lrrrrrrrrr@{}}   % numbers should be right aligned, text left aligned
\toprule
dataset & num\_pairs & num\_authors & num\_same\_pairs & num\_different\_pairs & avg\_text\_len & min\_text\_len & max\_text\_len & std\_text\_len & median\_text\_len \\ 
\midrule
pan20     & 66912 & 52778 & 35620 & 31292 & 21435.53  & 20670 & 296887  & 2685.49   & 21284.00  \\ 
blog      & 64771 & 18961 & 33639 & 31132 & 1846.20   & 501   & 615409  & 3461.74   & 1244.00   \\ 
gutenberg & 36    & 4     & 15    & 21    & 293840.11 & 14092 & 1176438 & 339991.16 & 139370.00 \\ 
\bottomrule
\end{tabular}%
}
\end{table}
\textcolor{red}{above len in characters, but I have also stats for wordsâ€š}


\subsubsection{Dataset Preprocessing}
\label{subsubsec:dataset_preprocessing}

To further control confounders influencing authorial style, we preprocess the dataset 
(once before creating the arrow dataset file and once before using the detector).
The requirements for the preprocessing are:
\begin{itemize}
    \item The \dataBlog{} arrow dataset is created by combining same- and different-author pairs of the same topic (control topic).
    \item The texts are stripped of all format/ layout information to obtain plain text \textcolor{red}{TODO: before saving them as arrow files}.
    \item The texts should be of similar length (detector crops texts to 110\% of the shorter text).
\end{itemize}
In order to produce a controlled testing environment four our imposter approach, 
we opted to refine few datasets rather than scaling up to larger datasets.
Removing layout information includes removing HTML artefacts, play artefacts, newlines, 
converting utf-8 to ASCII, lowercasing and stripping leading and trailing whitespace.

\subsubsection{Selection of Text Pairs}
\label{subsubsec:dataset_text_pair_selection}

\textcolor{red}{TODO:} \dataPan{} comes in an arrow dataset format, where text pairs are already selected.
As mentioned above, the \dataBlog{} dataset is created by combining same- and different-author pairs of the same topic (control topic). 
\textcolor{red}{TODO: Add more details and refine process itself.}
\textcolor{red}{TODO: refine and preprocess \dataGutenberg{} dataset pair selection. It is bad/random right now.}