\subsection{Dataset}
\label{subsec:dataset}

\subsubsection{Original Data}
Due to this approach extending the original imposter approach by \citet{koppel_determining_2014}, 
we first use original data to establish the feasibility and reproducibility of the original approach. 
\citet{koppel_determining_2014} used \dataBlog{} and the \dataStudent{} dataset.

% Blog
The \dataBlog{} dataset~\citep{blog_dataset_2006} is a collection of blog posts from \textit{blogger.com} on or before August 2004.
Each blog is the work of a single user.
According to kaggle~\footnote{\href{https://www.kaggle.com/datasets/rtatman/blog-authorship-corpus?resource=download}{Kaggle dataset \texttt{rtatman/blog-authorship-corpus}} (26.07.2025)},
the corpus contains \num{681288} posts from \num{19320} bloggers with approximately 35 posts and \num{7250} words per person.
Users are binned by age into the following categories: 13-17, 23-27, and 33-47.
Dataset features include \texttt{id}, \texttt{gender}, \texttt{age}, \texttt{topic}, 
\texttt{sign} (referring to the author's astrological/zodiac sign), \texttt{date}, and \texttt{text}.

% student essays
The \dataStudent{} dataset is not publicly available due to the presence of sensitive student information. 
We are grateful to J. W. Pennebaker for providing access to the original data used by M. Koppel in his study. 
The dataset comprises \num{7052} student essays written across five assignments from a 2006 university class of 950 students~\citep{koppel_determining_2014}.

The assignments include a stream-of-consciousness task, reflections on childhood, a self-assessment of personality, 
a thematic apperception test, and four examples of four different theories.
Following \citet{koppel_determining_2014}, we use the first four assignments for our imposter approach. 
Unlike their work, which truncates essays to the first 500 words, we utilize the full texts.

In line with \citet{koppel_determining_2014}, each disputed-candidate pair in our setup originates from different assignments, 
regardless of their class label (\texttt{same-author} or \texttt{different-author}).
It is worth noting that the filenames are inconsistently formatted: 
Most are named after the author ID, while those from the first assignment follow the pattern \texttt{2006\_authorID}.

Due to privacy considerations, we refer researchers seeking access to the \dataStudent{} dataset to J. W. Pennebaker, 
who remains the official data holder. 
For establishing a baseline in our imposter experiments, we use both the \dataBlog{} and \dataStudent{} datasets.


\subsubsection{Additional Data}
To extend our test scenario for the imposter approach, we opted to find additional datasets that 
(1) control confounders (e.g. genre, topic) and (2) provide undisputed authorship.
We found that both the \dataPan{} and \dataGutenberg{} datasets are suitable candidates.
The statistical properties of the datasets are shown in \autoref{tab:data_stats}.

% PAN20: Fanfiction
The \dataPan{} dataset~\citep{bischoff_importance_2020} is a collection of fanfiction texts from the \textit{fanfiction.net} website.
Texts belong to one fandom (i.e. thematic category), and there are not fanfiction crossovers.
According to \href{https://pan.webis.de/clef20/pan20-web/author-identification.html}{PAN's official website}, 
train and test set originate from two different fanfictions and approximate the (long-tail) distribution of the fandoms in the original dataset.
Dataset features include \texttt{id}, \texttt{fandoms}, and \texttt{pair} containing the text pairs.
They provide an additional \texttt{jsonl} file containing the ground truth for the pairs, 
i.e. \texttt{id}, \texttt{same}, and \texttt{authors} features.

% Gutenberg
The \dataGutenberg{} dataset~\footnote{\href{https://www.gutenberg.org/}{Project Gutenberg} (26.07.2025)} 
is a selection of literary works from the Project Gutenberg.
Project Gutenberg is an online library focusing on older works for which U.S. copyright has expired.
Volunteers have already digitized and proofread more than \num{75000} e-books.
In this case, we selected 19 works from 7 authors from the 16th and 19th century.
Genres include drama, fiction and poetry.
Metadata was manually extracted from the Project Gutenberg website.


\subsubsection{Dataset Preprocessing}
\label{subsubsec:dataset_preprocessing}

To further control confounders influencing authorial style, we preprocess the dataset 
(once before creating the arrow dataset file and once before using the detector).
The requirements for the preprocessing are:
\begin{itemize}
    \item The texts are stripped of all format/ layout information to obtain plain text before saving them as arrow files.
    \item The texts should be of similar length (detector crops texts to the length of the shorter text).
\end{itemize}
In order to produce a controlled testing environment for our imposter approach, 
we opted to curate small datasets rather than scaling up to larger datasets.
Removing layout information includes removing HTML artefacts, play artefacts, newlines, 
converting utf-8 to ASCII, and stripping leading and trailing whitespace.
We opted to forgo lowercasing the texts in order to preserve authorial capitalization.


\subsubsection{Selection of Text Pairs}
\label{subsubsec:dataset_text_pair_selection}

We had to select pairs of texts for the \dataBlog{}, \dataStudent{} and the \dataGutenberg{} dataset.
Eligible texts have a minimum length of \num{700} words for all datasets.
% We select a lower limit of \num{500} words for the \dataStudent{} dataset, 
% since the longest essay only contains \num{1136} words.
We decided to keep the existing pairs in the \dataPan{} arrow dataset for better comparability.
All datasets consist of same- and different-author pairs. 
As mentioned before, we aimed to control confounders when selecting pairs.
Find descriptive statistics for the preprocessed datasets in Table~\ref{tab:data_stats}.

% minimum length necessesary for AV/ AA
When selecting the minimum length of texts, we consulted related research in the field of \ac{av} and \ac{aa}.
\citet{bevendorff_generalizing_2019} use texts chunks of at least 700 words for their unmasking approach, 
where \citet{koppel_authorship_2004} set the minimum length to 500 words.
Recent work~\citep{llm_detection_av_2025} identifies a minimum length of \num{2500}-\num{4000} characters 
sufficient for effective \ac{llm} detection (framed as \ac{av} or \ac{aa}).
Therefore, they opted for a minimum length of \num{3000} characters for their datasets.

\begin{table}[h]
\centering\small
\caption{Statistics of preprocessed datasets \dataPan{}, \dataBlog{}, \dataGutenberg{}, and \dataStudent{}.}
\label{tab:data_stats}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lrrrrrrrrr@{}}   % numbers should be right aligned, text left aligned
\toprule
dataset & num\_pairs & num\_authors & num\_same\_pairs & num\_different\_pairs & avg\_text\_len & max\_text\_len\_words & std\_text\_len\_words & median\_text\_len\_words \\
\midrule
pan20           & 66905 & 52771 & 35616 & 31289 & 21418.76 (3914.76)   & 55413 & 512.19 & 3889 \\
blog            & 11565 & 5997  & 6204 & 5361  & 6249.94 (1154.25)     & 115365 & 1493.97 & 913 \\
gutenberg       & 12    & 7     & 6     & 6     & 437870.75 (78698.79) & 297704 & 68329.91 & 60282 \\
student\_essays & 224  & 222   & 112   & 112  & 4459.32 (865.90)     & 1634 & 157.41 & 815  \\
\bottomrule
\end{tabular}%
}
\end{table}

For the \dataBlog{} dataset, 
two texts of a pair are selected such that they share the same topic, year, gender and age, where the last to reference the text's author.
Train (80\%) and test split (20\%) have different topics.

For the \dataStudent{} dataset,
tasks are either in the train (70\%) or test (30\%) set.
The test set is bigger, since an author typically only writes one essay per task and if only one task is selected for the test set we can not create any same author pairs.
The pairs are selected such that their authors share the same sex, ethnicity, and political orientation.
Additionally, for different author pairs, the texts are selected such that they share the same task.

For the \dataGutenberg{} dataset,
we selected pairs of texts that share the same genre and century.
Authors can either be in the train (80\%) or test (20\%) set.

Irrespective of the information used to select pairs, the final dataset contains only the columns \texttt{authors}, \texttt{pair}, and \texttt{same}.
The \texttt{pair} column contains the texts of the pair as a list of strings,
the \texttt{authors} column contains the authors of the texts as a list of strings,
and the \texttt{same} column indicates whether the texts are from the same author (\texttt{True}) or from different authors (\texttt{False}).
