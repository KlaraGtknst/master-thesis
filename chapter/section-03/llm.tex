\section{Impact of \acs{llm} on Authorship Verification}
\label{sec:llm_impact}

With the advances in \ac{gai} come risks and opportunities.
\Acp{llm} as authors may undermine trust in the authenticity of digital texts, yet they also serve for valuable tools for strengthening regulatory approaches.
In \Cref{subsec:llm_authors}, we explain why \acp{llm} can be conceptualised as authors. 
Thereafter, we discuss how \acp{llm} affect discrimination in \ac{aa} tasks in \Cref{subsec:llm_discriminator}.

\subsection{\acsp{llm} as Authors}
\label{subsec:llm_authors}

There is no general definition of when a text is \ac{llm} generated rather than co-created by humans with \ac{llm} assistance.
% Obviously, fully generated texts should be marked as \ac{llm} generated.
Minor human edits of \ac{llm} generated texts do not change the fact that the core content was \ac{llm} generated.
If \acp{llm} are used for grammar checking, polishing, and editing suggestion, the primary substantial contribution was human.
One could denote these texts "\acs{ai}-revised Human-Written Text"~\citep{revised_2024}.

With advances of generative models with regard to mimicking human writing, we have to face the fact that \acp{llm} will play a crucial role in any authorship analysis related tasks from now on.
\citet{llm_detection_av_2025}\ claim that \ac{llm} detection is not an \ac{aa} task, i.e.\ a closed-set binary classification where both classes are sufficiently discriminative, but an \ac{av} task, i.e.\ an open-set one-class classification problem. 

% differences: also more in ~\citep{wang_stumbling_2024}
Despite these advances, there are still some statistical differences on \ac{llm} generated and human authored texts.
\ac{llm} generated texts lack lexical diversity, overuse certain adjectives (e.g.\ "innovative") and contain longer, more complex sentences.
Moreover, \acp{llm} possess stylistic fingerprints and memorise patterns from the training data.
% lengths
Furthermore, word length averages and distributions across genre differ for \acp{llm} and humans.
% future of LLMs
As \acp{llm} continue to produce increasingly human-like text, \ac{llm} detection is expected to more closely resemble human authorship classification tasks~\citep{llm_detection_av_2025}.


\subsection{\acsp{llm} as Discriminators}
\label{subsec:llm_discriminator}

While \acp{llm} can generate coherent text, their effectiveness as direct discriminators in \ac{aa} tasks varies. 
Words with similar meaning, such as "color" and "colour", are mapped to similar vector representations~\citep{altakrori_topic_2021}.
This reduces sensitivity to subtle differences in language, which are often critical for identifying an author. 
Consequently, relying on \acp{llm} as the primary discriminator in \ac{aa} or \ac{av} tasks may be suboptimal.

Rather than serving as standalone discriminators, \acp{llm} are more appropriately employed as supporting tools. 
For instance, they can generate cross-domain training data to improve model robustness. 
In regard to \ac{llm} detection, prior work~\citep{mao_raidar_2024} assessed the extent to which text changes under \ac{llm}-based paraphrasing, since machine-generated text tends to undergo minimal alteration, whereas human-authored text exhibits greater variation.
% Conversely, in contexts where privacy is a concern, \acp{llm} can facilitate author obfuscation through controlled paraphrasing. 