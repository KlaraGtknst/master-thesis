\subsection{\impAppr{}}
\label{sec:impostor_method_theory}

The \impAppr{} builds on the n-gram Unmasking method, which classifies authorship by measuring how quickly classifier accuracy declines under repeated feature subsampling~\citep{koppel_authorship_2004}. 
Whereas the n-gram Unmasking method relies on complex, interdependent projections, the \impAppr{} uses random projections to transform features into lower-dimensional spaces.
After each projection step, the method records how often a candidate author is predicted as the source of the text. 
The aggregated score across all elimination steps forms the basis for the final prediction~\citep{tyo_state_2022}.

\ac{av} is an open-set problem: the true author of an anonymous text may or may not be the candidate author. 
As \citet{koppel_determining_2014} argue, every closed-set \ac{aa} problem can be reduced to an \ac{av} problem. 
This reduction is achieved by testing each candidate author individually: if the verifier confirms authorship for exactly one candidate, attribution is successful. 
However, the reverse does not hold: solving closed-set \ac{aa} does not guarantee the ability to solve the more complex open-set \ac{av} problem.

Extending \ac{av}, \citet{koppel_determining_2014} introduce the many-candidates (or: open-set \ac{aa}) problem: given a large pool of candidate authors, determine which (if any) authored a given anonymous text. 

A key component of the \impAppr{} is the use of hard negative mining. 
The \impAppr{} generates impostor candidates to make verification more robust. 
In the \ac{aa} context, hard negatives are defined as text pairs from different authors that are nonetheless highly similar. 
To ensure difficulty, impostor texts must be drawn from the same domain as the candidate, where “domain” encompasses factors such as topic, genre, register, idiolect, or time period~\citep{bischoff_importance_2020}. 
The workflow described above is illustrated in \autoref{fig:impostor}.

The process is carried out twice for each pair of texts, swapping the roles of the disputed text and the candidate text. 
In this way, each text serves once as the disputed text and once as the reference for impostor generation. 
For each direction, a score is computed based on the number of times a candidate is identified as most similar to the disputed text across random feature reductions. 
The final prediction is obtained by averaging these scores and applying a threshold.


\begin{figure}[htbp]
    \centering
    \includesvg[width=\textwidth]{images/imposter/impostor.svg}
    \caption{\impAppr{} workflow: (1) Impostor generation, (2) creation of feature vectors using frequent n-grams, (3) random dimensionality reduction, (4) similarity computation and selection of the most similar candidate.}
    \label{fig:impostor}
\end{figure}



  \begin{definition}
    [n-gram]
    $n$ contiguous words also known as word collocations. \todo{cite, reference?\citep{koppel_authorship_2011}?}
    n-grams are no stylometric features \citep{altakrori_topic_2021}.
    % Quelle Martin Potthast Gespräch 19.05.2025:
    Tri-grams are commonly used in stylistic analysis, due to their ability to capture inflections, % Flexion/ Beugung in Deutsch
    morphemes, %  smallest meaningful constituents within a linguistic expression and particularly within a word
    and other syntactic structures for Germanic languages.
    Character-level $n$-gram features capture the frequency of $n$ consecutive characters in a text \citep{neal_surveying_2018}.
    The optimal $n$ is language dependent \citep{neal_surveying_2018}.
\end{definition}

\begin{definition}
    [Space free n-gram]
    Removing spaces from the $n$-gram reduces the number of $n$-grams.
    \citet{koppel_authorship_2011} use these definitions:
    \begin{enumerate}
        \item a string of $n$ characters that not include spaces
        \item a string of less than $n$ characters that is surrounded by spaces
    \end{enumerate}
\end{definition}



% \begin{definition}
%     [within-domain]
%     Experiments with P=Q.
%     Hence, it is necessary to ensure all texts are mutually from the same domain \citep{bischoff_importance_2020}.
%     \begin{table}[tbp]
%         \centering
%         \caption{Typical scheme $S_1$ for \ac{aa} problem instances, where A, B, are authors and P, Q domains and 
%         the vertical mapping denotes which author has written in which domain. 
%         For training, texts from A and B take turn; for testing, previously unseen texts from A and B are used \citep{bischoff_importance_2020}.}
%         \label{tab:within_domain_aa}
%         \begin{tabular}{|l|ll|ll|}
%         \hline
%         \textbf{Scheme $S_1$} & \multicolumn{2}{l|}{\textbf{training}} & \multicolumn{2}{l|}{\textbf{testing}} \\ \hline
%         \textbf{authors} & \multicolumn{1}{l|}{A} & B & \multicolumn{1}{l|}{A} & B \\ \hline
%         \textbf{domains} & \multicolumn{1}{l|}{P} & Q & \multicolumn{1}{l|}{P} & Q \\ \hline
%         \end{tabular}%
%     \end{table}
% \end{definition}


Explorative study on character n-gram proposed that character n-grams are successful in \ai{} tasks, due to their ability to capture different stylometry feature categories.
Affix (word end) n-grams capture morphology, and n-grams containing punctuation marks capture style information valuable for cross-domain settings.
Word n-grams capture topic information which is not necessary to obtain valid performance~\citep{Sapkota_ngrams_2015}.


\subsubsection{Traditional \imp{} Generation}
\label{subsubsec:traditional_impostor_generation}

\textcolor{red}{TODO: traditional impostor generation}


\citet{koppel_determining_2014} propose three \imp{} generation approaches.
The fixed approach randomly samples impostors from a fixed set of impostor documents having no special relation to the document pair in question.
They used aggregated results of random English Google queries.
The on-the-fly method first selects 50 small set of 3 to 5 random medium-frequency words from the candidate text.
Each set is used for a Google query.
Aggregate the top 25 results of the respective queries.
The results are considered impostors which are on-topic.
Blogs \imps{} are randomly chosen texts from bloggers.
\citet{koppel_determining_2014} state that these \imps{} belong to the same genre as the input text pair.



