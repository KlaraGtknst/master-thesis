\subsection{\impApprTitle{}}
\label{sec:impostor_method_theory}

\citet{koppel_determining_2014}\ propose reducing open-set \ac{av} to open-set \ac{aa}, or the so-called many-candidates problem, which determines which (if any) candidate author $a$ from a set of candidates $A$ authored a given anonymous text $d \in U$. 
We illustrate the hierarchy of problem complexity in \Cref{fig:problem_hierarchy}, based on their description.
The candidates of the open-set \ac{aa} problem are retrieved via hard negative mining. 
In the \ac{aa} context, hard negatives are defined as texts from different authors that are nonetheless highly similar. 
To ensure difficulty, impostor texts must be drawn from the same domain as the candidate, where domain encompasses factors such as topic, genre, register, or time period~\citep{bischoff_importance_2020}. 

\begin{figure}[htbp]
    \centering
    \includesvg{images/imposter/problem_hierarchy_complexity.svg}
    \caption[Problem hierarchy and complexity]{Problem hierarchy and complexity.}
    \label{fig:problem_hierarchy}
\end{figure}

The disputed text $d \in U$ and the candidate text $k_a \in K_a$ are encoded as vectors of \ac{tfidf} scores over the \num{100000} most frequent space-free character 4-grams.
Space-free character 4-garms are defined as sequences of four consecutive characters excluding spaces.
At word boundaries where fewer than four characters are available, the character sequence is padded with surrounding spaces to maintain a length of four characters~\citep{koppel_authorship_2011,neal_surveying_2018}. 
Illustrative examples are shown in \Cref{fig:spacefree_4gram}.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[node distance=3.5cm, every node/.style={font=\sffamily}]

    % Word nodes
    \node[draw, rounded corners, minimum width=2.4cm, minimum height=1cm, align=center] (word1) {face};
    \node[draw, rounded corners, minimum width=2.4cm, minimum height=1cm, right of=word1, align=center] (word2) {ial };
    \node[draw, rounded corners, minimum width=2.4cm, minimum height=1cm, right of=word2, align=center] (word3) {ed t};

    % Marks
    \node[right=-0.7cm of word1, text=green!70!black, scale=2] {\faCheck};
    \node[right=-0.7cm of word2, text=green!70!black, scale=2] {\faCheck};
    \node[right=-0.7cm of word3, text=red, scale=2] {\faTimes};

    % Labels
    \node[below=0.2cm of word1] {space-free 4-gram};
    \node[below=0.2cm of word2] {space-free 4-gram};
    \node[below=0.2cm of word3] {{$\boldsymbol{\neg}$} space-free 4-gram};

    \end{tikzpicture}
    \caption[Examples of space-free character 4-grams]{Examples of space-free character 4-grams.}
    \label{fig:spacefree_4gram}
\end{figure}

\citet{koppel_determining_2014} use character 4-grams based on prior experiments suggesting their effectiveness, though \citet{neal_surveying_2018} note that the optimal $n$ is language-dependent. 
Tri-grams are common in stylistic analysis of Germanic languages, capturing inflections, % Flexion/ Beugung in Deutsch
morphemes, %  smallest meaningful constituents within a linguistic expression and particularly within a word
and other syntactic structures. 
Word n-grams, which capture topic information, are generally avoided in authorship analysis, as topic information can hinder reliable attribution~\citep{neal_surveying_2018,Sapkota_ngrams_2015}.

The \impAppr{} extends \unmasking{}'s repeated feature subsampling \citep{koppel_authorship_2004} by applying random projections to reduce feature dimensionality.
After each projection, the method records whether text $k_a$ by the candidate author $a$ is most similar to the disputed text $d$, aggregating this score across all elimination steps~\citep{tyo_state_2022} (illustrated in \Cref{fig:impostor}). 
The procedure is repeated with the texts' roles swapped, so each text serves once as the disputed text and once as the reference. 
Final predictions are obtained by averaging the aggregated scores and applying a threshold.

\begin{figure}[htbp]
    \centering
    \includesvg[width=\textwidth]{images/imposter/impostor.svg}
    \caption[\impAppr{} workflow]{\impAppr{} workflow: (1) Impostor generation, (2) creation of feature vectors using frequent 4-grams, (3) random dimensionality reduction, (4) similarity computation and selection of the most similar candidate.}
    \label{fig:impostor}
\end{figure}

\citet{koppel_determining_2014} quantify similarity using cosine and min-max measures, defined in \Cref{eq:cosine_sim} and \Cref{eq:min_max_sim}, respectively. 
$x$ and $y$ denote vector representations of documents $d$ and $k_a$.
They report that min-max similarity yields predictions with higher accuracy than cosine similarity.

\begin{equation}
    \cos(\theta_{x,y})=\mathrm{sim}(x,y)=\frac{x^Ty}{\left\| x \right\|\left\| y \right\|}
    \label{eq:cosine_sim}
\end{equation}

\begin{equation}
    \operatorname{minmax}(x,y)=\frac{\sum_{i=1}^{n}\mathrm{min}(x_i,y_i)}{\sum_{i=1}^{n}\mathrm{max}(x_i,y_i)}
    \label{eq:min_max_sim}
\end{equation}

\subsubsection{Traditional \Imp{} Selection}
\label{subsubsec:traditional_impostor_generation}

\citet{koppel_determining_2014}\ introduce three \imp{} selection approaches. 
In the \texttt{fixed} approach, \imps{} are drawn randomly from a predetermined pool of documents unrelated to the input pair.
In their study, this pool consisted of texts collected from random English Google queries. 
The \texttt{on-the-fly} approach, by contrast, derives impostors based on the candidate text. 
Specifically, sets of three to five medium-frequency words are sampled from the text, each set is submitted as a Google query, and the top 25 results are aggregated. 
The retrieved documents serve as \imps{} that are, at least in theory, on-topic. 
Finally, in the \texttt{blog} approach, impostors are selected at random from the \dataBlog{} dataset. 
This method, according to the authors, ensures that impostor texts share the same genre as the input pair.

For simplicity, we refer to our implementation of random \imp{} selection from the same dataset as the candidate text as the \texttt{fixed} approach. 
Thus, in our context, the \texttt{fixed} approach differs conceptually from the original \texttt{fixed} and \texttt{blog} approaches.

First the $m$ most similar impostor documents in terms of min-max similarity are selected.
Then, $n < m$ random impostor documents are selected.
\citet{koppel_determining_2014}\ found that using a selection of $n$ \imps{} rather than all $m$ impostor documents produces better results.
The approach is insensitive to $m$ and $n$.