% LLM detection
\ac{llm} detection denotes the task of determining whether a text was written by a human or an \ac{llm}.
% motivation
Due to the recent advances in \acp{llm} enabling them to mimic human writing styles, they have become widely used across a variety of tasks.
While this may be beneficial to increase productivity for programmers or in offices, it also introduces new opportunities for misuse, such as generation of fake news or impersonation of individuals.
Schools and universities face the challenge of detecting \ac{llm} generated texts in student assignments, thereby not only decreasing the amount students learn, but also binding resources of teachers to detect such texts.
In light of these developments, a rightful call for robust high-precision \ac{llm} detection methods has emerged.

% specificity rather than generality
In the context of \ac{llm} detection, generalized solutions are models trained once on a given dataset and then applied indiscriminately to all texts, regardless of contextual factors such as text domain or topic. 
% bhattacharjee_fighting_2024: ChatGPT not equally good across different LLMs
% li_learning_2025: Scores drop for Out of Distribution (OOD) texts
However, existing research indicates that many such models struggle to reliably detect all \acp{llm} especially in \ac{ood} scenarios~\citep{bhattacharjee_fighting_2024,li_learning_2025}.
Based on this evidence, we argue that \ac{llm} detection methods should be tailored to specific scenarios rather than relying on generalized approaches.
In particular, we focus on single case solutions, i.e. models trained specifically for a particular scenario.
Formally, single case solutions involve creating \ac{id} \ac{llm} detection scenarios where ll variables are controlled by training a new model for each dataset.

% AV
Given the ability of \acp{llm} to generate text closely resembling human writing, we can conceptualize \acp{llm} as one or multiple distinct authors.
This perspective allows us to frame \ac{llm} detection as an \ac{av} task, where given two texts (i.e. one of unknown authorship and one known to be generated by an \ac{llm} author) the objective is to determine whether they share the same author.
Building on extensive existing research in \ac{av}, which has developed promising methods for comparing textual authorship, we leverage and extend one of these techniques to address the unique challenges posed by \ac{llm} authors. 
This work adapts impostor method by \citet{koppel_determining_2014} to improve the detection of \acp{llm}, bridging gaps between traditional authorship verification and modern \ac{llm} detection.
We aim to enhance the impostor approach by addressing its limitations, particularly the lack of control over contextual variables when generating impostor texts.
We achieve this by proposing a novel impostor generation method that leverages state-of-the-art \acp{llm} to produce hard negative impostor texts.
% AA
% Given set of texts generated by \acp{llm} and a text of unknown authorship,
% the task can be framed as open-set \ac{aa} problem, 
% where the goal is to determine whether the text was written by one of the \acp{llm} or not.
% % Genre
% It can also be framed as a genre classification task, where the goal is to determine whether a text belongs 
% to the genre human or to the genre \ac{lm} \todo{Martins neues Paper}.
% % One-class classification
% It can be framed as a one-class classification task, where all \ac{lm} authors are considered as one class.
% The goal is to identify \ac{lm} generated texts with high confidence/ \todo{precision?}.

