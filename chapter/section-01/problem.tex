% motivation
Historically, authorship analysis focused on literary disputes, such as the authorship of Shakespearean plays~\citep{neal_surveying_2018,stamatatos_survey_2009}, but contemporary concerns have shifted towards applications with everyday relevance.
In an era where large amounts of text can be copied, paraphrased, or fabricated with ease, identifying the true author of a text is crucial for maintaining trust in communication. 

Traditionally, the goal is to determine who, if any, from a candidate set of authors produced a disputed text, a task formally denoted as \ac{aa}. 
For instance, in the case of Shakespearean plays, the candidate set might be constructed from literate individuals of the period.
However, the true author may lie outside this set, necessitating that any \ac{aa} method retain the option to abstain from assigning authorship. 
A strategy is to adopt a divide-and-conquer approach, evaluating each candidate individually~\citep{tyo_state_2022,barlas_cross_domain_2020}. 
These pairwise evaluations, formally referred to as \ac{av} tasks, aim to determine whether two texts were written by the same individual~\citep{koppel_authorship_2004}. 

% specificity rather than generality
Existing approaches to generalisation typically train a single model and apply it across domains.
Despite significant advances in \ac{av}, prior work finds that such models struggle in out-of-distribution settings, where the topic or genre diverges from the training data~\citep{Sundararajan_style_18,bischoff_importance_2020,li_learning_2025}. 
This shortcoming motivates a shift towards scenario-specific solutions, where models are trained anew for narrowly defined cases. 
Such scenario-specific approaches enable more precise control over domain variables which facilitates emphasising on stylistic idiosyncrasies rather than domain-level variation.

% AV
One important scenario-specific method is the \impAppr{} by \citet{koppel_determining_2014}.
It introduces the idea of sampling so-called \imp{} texts, i.e.\ hard negatives, intended to sharpen the discrimination between genuine and false authorship matches. 
Since impostor texts are drawn anew for every input text pair, the method should generalise well in cross-domain scenarios.
However, the method's effectiveness is limited by the quality and contextual adequacy of these \imp{} texts. 
Traditional strategies cannot simultaneously control multiple confounding factors such as genre, topic, and target audience, limiting the discriminatory power of the hard negatives.

This thesis extends the \impAppr{} by leveraging state-of-the-art \acp{llm} to generate paraphrases as \imps{} rather than sampling existing texts.
This allows for simultaneous control over multiple confounding factors.
We collected the original datasets and applied a controlled candidate-pair selection procedure aligned with the work by \citet{koppel_determining_2014}, to ensure a robust evaluation setup.
The extended \impAppr{} outperforms the original sampling strategies, \unmasking{} and \acs{ppmd}, on the \dataStudent{} dataset at specific operating points in the precisionâ€“recall space.
