\chapter{Introduction}
\label{chap:introduction}

\input{chapter/section-01/problem}

\section{Research Questions}
\label{sec:research_questions}
We formulate the following research questions to investigate whether LLM-generated paraphrases can improve the effectiveness of the impostor method by providing better control over confounding factors than traditional hard negative sampling strategies.
\begin{questions}
    \item \textbf{How suitable are \acp{llm} for \imp{} generation?} \label{enum:rq1} \hfill \\
    For \imps{} to be effective, hard negatives need to adhere to constraints similar to the candidate text, including confounding variables such as genre, topic, and target audience.
    We employ \ac{llm}-based paraphrasing model the original confounding variables. 
    By conditioning \acp{llm} on confounding variables, the \impAppr{} emphasises differences in authorial style rather than in content. 
    However, the precise syntactic similarity threshold at which paraphrases are attributable to the candidate author remains uncertain, potentially limiting detection accuracy. 
    % To investigate the suitability of artificial \imp{} generation, we design an experiment that contrasts one-step \imp{} generation with traditional baselines using standard classification metrics.

    \item \textbf{Which metrics are appropriate to evaluate the quality of generated \imps{}?} \label{enum:rq2} \hfill \\
    Assessing \imps{} requires evaluating paraphrases, a task complicated by the absence of a universally accepted definition of paraphrasing. 
    Prior work often adopts evaluation metrics from adjacent \ac{nlp} tasks such as machine translation and summarisation~\citep{gohsen_captions_2023}. 
    The two central dimensions are semantic similarity and syntactic similarity. 
    Contrary to naive assumptions, high syntactic similarity is not always desirable, as it may indicate minimal modification of the original text.
    Instead, the objective is to achieve strong semantic similarity with sufficient syntactic variation, typically measured by automatic scores, while a subset of samples additionally validated through human judgments of adequacy.
    % We therefore construct experiments to evaluate paraphrases using \acl{sota} measures for paraphrase quality. 

    \item \textbf{How does the \ac{llm}-based \impAppr{} perform compared to established \ac{av} methods?} \label{enum:rq3} \hfill \\
    To benchmark our approach, we compare it against baselines introduced by \citet{koppel_determining_2014}, \unmasking{}, and \acs{ppmd}.
    % , \textcolor{red}{as well as \unmasking{} and compression-based \ac{ppmd}}. 
    The evaluation is conducted on human-authored text pairs from the \dataStudent{} dataset used in the original study, measuring performance in terms of precision and recall.
    
\end{questions}



\section{Contributions}
\label{sec:contributions}
The main contributions of this thesis are as follows:
\begin{itemize}
    \item Collection and preprocessing of original datasets, including a controlled candidate-pair selection procedure aligned with the methodology of \citet{koppel_determining_2014} and informed by direct consultation with the authors (cf.~\Cref{sec:dataset}).
    \item Reimplementation of the traditional \impAppr{}~\citep{koppel_determining_2014}\ (cf.~\Cref{sec:impostor_method_theory}).
    \item Development of an \ac{llm}-based \impAppr{} extending the work of \citet{koppel_determining_2014} as a scenario-specific solution to \ac{av} problems even in cross-domain settings (cf.~\Cref{sec:impostor_generation}). 
    \item Analysis of prompt design and its influence on paraphrase length as a confounding variable (cf.~\Cref{subsec:prompt_impact_res}/~\ref{enum:rq1} and \ref{enum:rq2}).
    \item Quantitative comparison of paraphrasing approaches using metrics adapted from summarisation and translation tasks (hereafter paraphrasing scores) (cf.~\Cref{sec:comp_paraphrases}/~\ref{enum:rq2}).
    \item Analysis of the effect of text segmentation (i.e. number of chunks) on paraphrasing scores (cf.~\Cref{sec:results_chunks}/~\ref{enum:rq2}).
    \item Evaluation of the proposed \ac{llm}-based \impAppr{} against established \ac{av} techniques, specifically the baselines introduced by \citet{koppel_determining_2014}
    % , \textcolor{red}{\unmasking{} and \ac{ppmd}}, 
    within the traditional \ac{av} setting using pairs of human-authored texts (cf.~\Cref{subsec:imp_gen_res}/~\ref{enum:rq3}).
   
\end{itemize}



\section{Thesis Structure}
\label{sec:thesis_structure}

The remainder of this thesis is organised as follows: 
To begin, \Cref{chap:authorship_identification} provides the background on \ac{av}, covering early approaches, \acl{sota} methods, stylometry, and practical applications.
\Cref{chap:related_work} then examines related research in greater detail.
Building on this, \Cref{chap:llm_impostor_method} introduces our extension to the \impAppr{}.
The experimental work is detailed in \Cref{chap:experimental_setup}, with \Cref{chap:experimental_results} presenting the corresponding results.
Finally, \Cref{chap:discussion} interprets the findings, and \Cref{chap:conclusion} summarises the thesis while outlining directions for future research.
