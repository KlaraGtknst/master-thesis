\chapter{Introduction}
\label{chap:introduction}



\input{chapter/section-01/problem}

% \section*{Research Questions}
% \label{sec:research_questions}
To guide this objective, we formulate the following research questions:
\begin{questions}
    \item \textbf{How can we instruct a \ac{llm} to paraphrase the text of a candidate author such that it captures the \ac{llm}'s stylistic properties?} \label{enum:rq1} \hfill \\
    The goal is to create hard negatives for the Impostor method by controlling contextual factors.
    By controlling genre, topic and other factors, similarity measures primarily focus on differences in authorial style rather than the impact of content on style.
    We obtain this controlled environment by utilizing \acp{llm} to paraphrase the original text.
    There are different approaches to paraphrasing text using \acp{llm}.
    They include (a) directly asking the \ac{llm} to paraphrase the text, 
    (b) first extracting specific information from the original text and subsequently generating a paraphrase based on the information.
    This thesis compares both approaches on \dataStudent{}, \dataBlog{}, \dataGutenberg{} and \dataPan{}.

    \item \textbf{How do we evaluate the quality of paraphrases?} \label{enum:rq2} \hfill \\
    Paraphrase evaluation is inherently challenging, as there is no universally agreed-upon definition of what constitutes a paraphrase. 
    Prior research often adapts evaluation metrics from related \ac{nlp} tasks such as machine translation or summarization. 
    Two key dimensions are typically considered: semantic similarity and syntactic similarity.
    Contrary to initial intuition, high syntactic similarity is not necessarily desirable, as it may indicate that the \ac{llm} has merely copied the original text with minimal changes. 
    Instead, our focus lies on achieving high semantic similarity while maintaining syntactic diversity to ensure genuine rephrasing.
    Furthermore, we acknowledge that relatively low automatic scores can still be acceptable if qualitative human evaluation confirms the paraphraseâ€™s adequacy.

    % \item \textbf{Which features are used for the \ac{av} problem?} \label{enum:rq3} \hfill \\
    % Traditional features include character tri-gram features, while newer research has proposed using \ac{llm} such as BERT.

    \item \textbf{How does the \ac{llm}-based impostor approach perform compared to state-of-the-art models?} \label{enum:rq4} \hfill \\
    Though our approach is computationally expensive, we argue that it is not a general purpose \ac{llm} detection method, but rather a single case solution tailored to specific detection tasks.
    We evaluate its performance in scenarios where (a) the disputed text is human generated,
    (b) the disputed text is \ac{llm} generated and the candidate is the same \ac{llm}, and
    (c) the disputed text is \ac{llm} generated, but the candidate is a different \ac{llm}.
    In terms of performance, we compare our method to other \ac{av} approaches on the \dataStudent{}, \dataBlog{}, \dataGutenberg{} and \dataPan{} datasets.
    
\end{questions}

% \section*{Idea}
% \label{sec:idea}

% Given a text of unknown authorship (i.e., human or \ac{llm}), 
% construct a set of impostor texts using state-of-the-art \acp{llm} based on the original text.
% Obtain the author by \ac{aa}/ \ac{av} methods, such as unmasking, to \textit{confidently}, i.e. high precision, identify \ac{llm} generated texts
% (and possibly which \ac{llm}).



% \section*{Contributions}
% \label{sec:contributions}
The contributions of this thesis are:
\begin{enumerate}
    \item Reimplementation of the traditional Impostor approach (cf. \autoref{chap:implementation}).
    \item Extension of the impostor approach with \ac{llm} generated impostors for line-up of difficult opponents (cf. \autoref{chap:methodology}). 
    \item Frame \ac{llm} detection as a \ac{av} problem and use \ac{llm} generated text as candidate for text of "unknown" authorship.
\end{enumerate}
