\paragraph{\ac{bleu}.}
\ac{bleu}~\citep{papineni_bleu_2001} was originally developed for machine translation evaluation~\citep{zhou_paraphrase_2021,anantha_pearson_metrics_2021}. 
\ac{bleu}'s basic unit of evaluation is a sentence. 
\ac{bleu} is based on precision, i.e.\ computing the fraction of generated candidate word n-grams that appear in any reference text over the total number of word n-grams in the generated candidate text~\citep{kurt_pehlivanoglu_comparative_2024,palivela_optimization_2021,papineni_bleu_2001,anantha_pearson_metrics_2021}. 
In our case, there is only one reference $r$, multiple candidates $c \in \mathcal{C}$ and multiple n-grams in each candidate $c$.
% We consider the reference the ground truth text.
To prevent inflated precision scores $p_n$ due to repetition of frequent tokens (e.g.\ "the"), \ac{bleu} introduces a clipping mechanism $\operatorname{Count_{match}}(.)$ that caps n-gram counts at their maximum reference frequency~\citep{papineni_bleu_2001}. 
Precision $p_n$ for $n \in \mathbb{N}_{>0}$ is given by \Cref{eq:bleu}.

\begin{equation}
    p_n = \sum_{c \in \mathcal{C}} \sum_{n\text{-}gram \in c} \frac{\operatorname{Count_{match}}(n\text{-}gram)}{\operatorname{Count}(n\text{-}gram)}
\label{eq:bleu}
\end{equation}

The choice of $n$ determines what syntactic characteristic is evaluated.
Uni-grams are used to test adequacy, while longer n-grams are used to test fluency~\citep{papineni_bleu_2001}. 
The brevity penalty $\operatorname{BP}$ from \Cref{eq:bleu_brevity_penalty} is applied to discourage excessively short candidates $c$~\citep{papineni_bleu_2001}.

\begin{equation}
    \operatorname{BP} = \begin{cases}
        1 & \text{if } \operatorname{len}(c) > \operatorname{len}(r) \\
        e^{1 - \frac{r}{c}} & \text{else}
    \end{cases}
\label{eq:bleu_brevity_penalty}
\end{equation}

In order to compute the \ac{bleu} score from \Cref{eq:bleu} for more than one sentence, 
one (1) computes the clipped n-gram matches sentence by sentence, 
then (2) adds them across all sentences, 
and finally (3) divides the total clipped n-gram matches by 
the total number of unclipped n-grams in all candidate sentences~\citep{papineni_bleu_2001,cordeiro_bleu_2007}.

Combined scores across different n-gram orders are computed via the geometric mean, weighted uniformly (i.e.\ $w_n$) across different $n$~\citep{papineni_bleu_2001,banerjee_METEOR_2005}.
Combining the precision $p_n$ from \Cref{eq:bleu} and brevity penalty $\operatorname{BP}$ from \Cref{eq:bleu_brevity_penalty} leads to the final score, as defined in \Cref{eq:bleu_final}.

\begin{equation}
    \operatorname{BLEU} = \operatorname{BP}  \exp\left(\sum_{n=1}^{N} w_n  \log p_n\right)
\label{eq:bleu_final}
\end{equation}

\ac{bleu} disregards semantic similarity completely and therefore judges paraphrases only based on n-gram overlap. 
As such, it is generally recommended to be supplemented with human evaluation~\citep{zhou_paraphrase_2021}.



% Its values range from 0 to 1 \citep{papineni_bleu_2001}.

% \ac{bleu} automatically penalises n-grams appearing in the candidate text but not in the reference text, 
% as well as n-grams appearing more often in the candidate than in the reference text \citep{papineni_bleu_2001}.

% For multiple sentences, they (1) add the best match (among the reference texts) length for each candidate sentence, 
% and (2) divide this sum $r$ by the total length of all candidate sentences $c$. 
% They cannot use recall for length-related problems here, 
% because \ac{bleu} uses multiple reference texts, which may have different lengths \citep{papineni_bleu_2001,banerjee_METEOR_2005}.
% If the generated candidate is significantly shorter than the reference text, the brevity penalty $\operatorname{BP}$ is applied.
% A \ac{bleu} score approaching 1 signifies the candidate matches one reference almost exactly \citep{papineni_bleu_2001}, 
% and thus, limited syntactic diversity (i.e.\ inadequate paraphrase) \citep{kurt_pehlivanoglu_comparative_2024}.
% Note that more reference texts lead to higher \ac{bleu} scores \citep{papineni_bleu_2001}.