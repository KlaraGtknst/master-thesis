
\paragraph{METEOR.}
% Its values range from 0 to 1 \citep{kurt_pehlivanoglu_comparative_2024}.
$\operatorname{METEOR}$ was proposed to address the limitations of \ac{bleu}. 
Unlike \ac{bleu}, $\operatorname{METEOR}$ explicitly incorporates recall. 
We consider $\operatorname{METEOR}$ primarily a syntactic metric due to its conceptual similarity to \ac{bleu}, but it also captures semantic aspects through stemming and synonym matching modules~\citep{kurt_pehlivanoglu_comparative_2024}. 

The order of modules reflects their priority in the alignment process. 
When the first module is exact matching, all possible mappings of candidate word unigrams to exact matches in the reference text are considered. 
Although valid alignments may restrict each unigram to a single mapping, multiple mappings are allowed in this initial stage. 
In the second stage, the best subset of unigram mappings is selected according to cardinality and minimal crossing. 
Unigrams that have not yet been mapped are then eligible for alignment using the next module in order, such as Porter-stemmed matching or synonym matching, producing multiple sets of mappings between candidate and reference. 
From the resulting alignments, $\operatorname{METEOR}$ computes a weighted $\mathrm{F}$-score, as defined in \Cref{eq:meteor}. 
In this formulation, unigram precision $\operatorname{P}$ is the fraction of candidate unigrams that are mapped to reference unigrams relative to the total number of candidate unigrams. 
Conversely, unigram recall $\operatorname{R}$ is the fraction of candidate unigrams that are mapped to reference unigrams relative to the total number of reference unigrams~\citep{banerjee_METEOR_2005}.

\begin{equation}
    \operatorname{METEOR} = \operatorname{F_{mean}} = \frac{10  \operatorname{P}  \operatorname{R}}{\operatorname{R} + 9  \operatorname{P}}  (1 - \mathrm{Penalty})
\label{eq:meteor}
\end{equation}

The penalty function discourages fragmented alignments, reducing the score by up to 50\% if bigram or longer matches are absent~\citep{banerjee_METEOR_2005}. 
$\operatorname{METEOR}$ correlates more strongly with human judgments than \ac{bleu}, particularly at the sentence or segment level, due to its sensitivity to lexical and semantic variation~\citep{zhou_paraphrase_2021,kurt_pehlivanoglu_comparative_2024}.


% \tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!30]
% \tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!20]
% \tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
% \tikzstyle{arrow} = [thick,->,>=stealth]


% \begin{figure}[h!]
% \centering
% % \resizebox{\textwidth}{!}{%
% \begin{tikzpicture}[node distance=2.5cm, every node/.style={minimum width=3cm, minimum height=1cm, text centered, draw, fill=blue!20}]

% % Nodes in a circular layout
% \node (start) [rectangle, rounded corners, fill=red!30] at (90:4cm) {Candidate \& Reference Sentences};
% \node (matching) at (30:4cm) {Matching};
% \node (bestsubset) at (150:4cm) {Select Subset of Mappings};
% \node (fscore) at (180:4cm) {Compute F-Score};
% \node (end) [rectangle, rounded corners, fill=red!30] at (200:4cm) {$\operatorname{METEOR}$ Score};

% % Arrows
% \draw[->, thick] (start) -- (matching);
% \draw[<->, thick] (matching) -- (bestsubset);
% \draw[->, thick] (bestsubset) -- (fscore);
% \draw[->, thick] (fscore) -- (end);

% \end{tikzpicture}%
% % }
% \caption{Circular visualisation of $\operatorname{METEOR}$ score computation steps, from candidate and reference sentences to the final weighted F-score with penalty.}
% \label{fig:meteor_circular}
% \end{figure}


