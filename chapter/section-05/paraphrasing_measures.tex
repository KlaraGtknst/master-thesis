
\subsection{Paraphrase Evaluation}
\label{subsec:paraphrase_evaluation}

There is no universal definition of what constitutes a paraphrase. 
Definitions vary in degree of semantic equivalence required. 
This conceptual ambiguity makes the task of evaluation especially challenging, since different applications may prioritize different aspects such as fidelity to meaning, stylistic variation, or grammatical well-formedness.
Because of this, paraphrase evaluation must account both for syntactic diversity and for the extent to which semantic content is preserved. 

Existing approaches can broadly be grouped into automatic and human-based methods. 
Automatic measures attempt to quantify the similarity between a candidate and a reference paraphrase using algorithmic techniques. 
These methods can be further distinguished by the linguistic level at which they operate. 
Some focus on syntactic structure, while others evaluate semantic preservation~\citep{gohsen_captions_2023}. 
Human evaluation, in contrast, remains the gold standard, as it naturally incorporates all of these dimensions.
In the following, we focus on both automatic evaluation strategies. 

\input{chapter/section-05/quantitative_evaluation_metrics.tex}


% \subsubsection{Qualitative Evaluation}
% \label{subsec:qualitative_evaluation}

% Human qualitative evaluation can combine syntactic and semantic dimensions more reliable than any automatic metric proposed.
% Naturally, when being asked to evaluate the quality of a paraphrase, individuals will score syntactic difference from the reference text, the readability from the paraphrase and semantic similarity to the reference text.
% Evaluation is usually formalized via a Likert scale~\citep{gohsen_captions_2023}.
