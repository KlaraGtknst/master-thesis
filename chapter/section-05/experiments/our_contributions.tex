\subsection{Exp.\ 5: Comparing Authorship Verification Methods}% in Traditional Human-Human Scenario}
\label{subsec:imp_gen}

We want to answer the question of how our \ac{llm}-based \impAppr{} performs compared to the traditional \impAppr{} across different generation methods and compared to standard baselines~\citep{koppel_determining_2014} %, and compared to (b) \acl{sota} \ac{av} methods 
in the traditional \ac{av} scenario.
We thus sample 5 same- and 5 different-author pairs from the \dataStudent{}. % (llm_detection_scenarios.py)
The supervised baseline is trained on the training data avoiding information leakage from training to our test results.
The \impAppr{} 
%and \unmasking{} 
detector configuration is shown in \Cref{tab:exp5_imp_config}. %and \Cref{tab:exp5_unmasking_config}, respectively.
For each \ac{av} method, we computed precision and recall across different thresholds. 

\begin{table}[h]
\centering\small
\caption{Exp.\ 5: \impAppr{} configurations.}
\label{tab:exp5_imp_config}
\begin{tabular}{@{}rlrrl@{}}   % numbers should be right aligned, text left aligned
\toprule
\# Impostors & Generation & Rounds & Top $n$ & Upsample \\
\midrule
50 & \textit{Variable} & 100 & \num{100000} & False \\
\bottomrule
\end{tabular}%
\end{table}

% \begin{table}[h]
% \centering\small
% \caption[Exp.\ 5: Unmasking configurations.]{Exp.\ 5: Unmasking configurations. CV denotes cross-validation.}
% \label{tab:exp5_unmasking_config}
% \begin{tabular}{@{}rrrrl@{}}   % numbers should be right aligned, text left aligned
% \toprule
% \# CV Folds & \# Chunks & Rounds & Top $n$ & Upsample \\
% \midrule
% 3 & 60 & 30 & \num{250} & False \\
% \bottomrule
% \end{tabular}%
% \end{table}


