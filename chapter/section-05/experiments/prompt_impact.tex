\subsection{Exp.\ 4: Comparing Prompts}
\label{subsec:prompt_impact_setup}

Since the \impAppr{} relies on paraphrased texts as a basis for further computation, it is crucial to ensure that these paraphrases are both on topic and of comparable length as their reference.  
Large variations in length may introduce confounding effects, diminishing the reliability of subsequent analyses.
This experiment aimed to investigate how different prompting strategies affect the quality of paraphrases generated by \acp{llm}. 
Specifically, it was designed to address two key questions:
\begin{enumerate}
\item How strongly does the choice of prompt influence the length of generated paraphrases $p$ relative to their reference text $r$ across different \acp{llm}?
\item Which prompt most effectively mitigates the confounding effect of paraphrase length?
\end{enumerate}

We designed three prompt variants (cf. \Cref{subsec:one_step_paraphrasing_prompts}) to instruct models in the paraphrasing task.
The first prompt, i.e.\ \texttt{prompt0}, directs the model to paraphrase by substituting the main subject, verb, and object with synonyms, keeping the output close in length to the reference.  
The second prompt, i.e.\ \texttt{prompt1}, requests a paraphrase that varies wording and sentence structure while preserving tone, with length similar to the original.  
The third prompt, i.e.\ \texttt{prompt2}, instructs the model to produce a paraphrase three times longer than the reference, while preserving meaning and tone. 

We selected reference texts from our datasets and applied the prompts to four causal \acp{llm}. 
The models include \texttt{meta-llama-3.1-8b-instruct}, \texttt{mistral-large-instruct}, \texttt{qwen3-32b}, and \texttt{openai-gpt-oss-120b}.
Further architectural details are provided in Appendix \ref{app:language_models}. 

We generated paraphrases for each modelâ€“prompt pair.
The evaluation focused on two main aspects. 
Since length acts as a confounding variable for \imps{}, we measured the relative length difference $d = \frac{\mathrm{len}(p)}{\mathrm{len}(r)}\times 100 \%$ between each reference text $r$ and its paraphrase $p$. 
Additionally, we manually inspected long paraphrases and those of similar length to their references to verify semantic preservation and readability.
